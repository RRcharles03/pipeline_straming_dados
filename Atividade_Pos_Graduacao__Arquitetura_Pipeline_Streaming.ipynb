{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJS-LACxbwzy",
        "outputId": "3adea194-c3f5-4e66-d8e3-8449384a353b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,372 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,745 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,673 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,682 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,995 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,235 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,947 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,533 kB]\n",
            "Fetched 25.6 MB in 3s (8,740 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Repository: 'deb https://ppa.launchpadcontent.net/ansible/ansible/ubuntu/ jammy main'\n",
            "Description:\n",
            "Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy. Avoid writing scripts or custom code to deploy and update your applications— automate in a language that approaches plain English, using SSH, with no agents to install on remote systems.\n",
            "\n",
            "http://ansible.com/\n",
            "\n",
            "If you face any issues while installing Ansible PPA, file an issue here:\n",
            "https://github.com/ansible-community/ppa/issues\n",
            "More info: https://launchpad.net/~ansible/+archive/ubuntu/ansible\n",
            "Adding repository.\n",
            "Adding deb entry to /etc/apt/sources.list.d/ansible-ubuntu-ansible-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/ansible-ubuntu-ansible-jammy.list\n",
            "Adding key to /etc/apt/trusted.gpg.d/ansible-ubuntu-ansible.gpg with fingerprint 6125E2A8C77F2818FB7BD15B93C4A3FD7BB9C367\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:8 https://ppa.launchpadcontent.net/ansible/ansible/ubuntu jammy InRelease [18.0 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://ppa.launchpadcontent.net/ansible/ansible/ubuntu jammy/main amd64 Packages [1,076 B]\n",
            "Fetched 19.1 kB in 1s (13.2 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  ansible-core python-babel-localedata python3-babel python3-bcrypt\n",
            "  python3-certifi python3-chardet python3-idna python3-jinja2 python3-jmespath\n",
            "  python3-kerberos python3-markupsafe python3-nacl python3-ntlm-auth\n",
            "  python3-packaging python3-paramiko python3-requests\n",
            "  python3-requests-kerberos python3-requests-ntlm python3-resolvelib\n",
            "  python3-tz python3-urllib3 python3-winrm python3-xmltodict python3-yaml\n",
            "  sshpass\n",
            "Suggested packages:\n",
            "  python-jinja2-doc python-nacl-doc python3-gssapi python3-invoke\n",
            "  python3-openssl python3-socks python-requests-doc\n",
            "The following NEW packages will be installed:\n",
            "  ansible ansible-core python-babel-localedata python3-babel python3-bcrypt\n",
            "  python3-certifi python3-chardet python3-idna python3-jinja2 python3-jmespath\n",
            "  python3-kerberos python3-markupsafe python3-nacl python3-ntlm-auth\n",
            "  python3-packaging python3-paramiko python3-requests\n",
            "  python3-requests-kerberos python3-requests-ntlm python3-resolvelib\n",
            "  python3-tz python3-urllib3 python3-winrm python3-xmltodict python3-yaml\n",
            "  sshpass\n",
            "0 upgraded, 26 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 25.1 MB of archives.\n",
            "After this operation, 245 MB of additional disk space will be used.\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security/main amd64 python3-jinja2 all 3.0.3-1ubuntu0.4 [108 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-yaml amd64 5.4.1-1ubuntu1 [129 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/ansible/ansible/ubuntu jammy/main amd64 ansible-core all 2.17.9-1ppa~jammy [1,017 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 python-babel-localedata all 2.8.0+dfsg.1-7 [4,982 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/ansible/ansible/ubuntu jammy/main amd64 ansible all 10.7.0-1ppa~jammy [17.9 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-tz all 2022.1-1ubuntu0.22.04.1 [30.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-babel all 2.8.0+dfsg.1-7 [85.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-markupsafe amd64 2.0.1-2build1 [12.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-packaging all 21.3-1 [30.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-resolvelib all 0.8.1-1 [23.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-certifi all 2020.6.20-1 [150 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-chardet all 4.0.0-1 [98.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-idna all 3.3-1ubuntu0.1 [52.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-jmespath all 0.10.0-1 [21.7 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-kerberos amd64 1.1.14-3.1build5 [23.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-nacl amd64 1.5.0-2 [63.1 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-ntlm-auth all 1.4.0-1 [20.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-bcrypt amd64 3.2.0-1build1 [32.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-paramiko all 2.9.3-0ubuntu1.3 [134 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-urllib3 all 1.26.5-1~exp1ubuntu0.2 [98.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-requests all 2.25.1+dfsg-2ubuntu0.1 [48.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-requests-kerberos all 0.12.0-2 [11.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-requests-ntlm all 1.1.0-1.1 [6,160 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-xmltodict all 0.12.0-2 [12.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-winrm all 0.3.0-2 [21.7 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 sshpass amd64 1.09-1 [11.7 kB]\n",
            "Fetched 25.1 MB in 2s (14.3 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 26.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-yaml.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3-yaml_5.4.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Selecting previously unselected package python-babel-localedata.\n",
            "Preparing to unpack .../01-python-babel-localedata_2.8.0+dfsg.1-7_all.deb ...\n",
            "Unpacking python-babel-localedata (2.8.0+dfsg.1-7) ...\n",
            "Selecting previously unselected package python3-tz.\n",
            "Preparing to unpack .../02-python3-tz_2022.1-1ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-tz (2022.1-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-babel.\n",
            "Preparing to unpack .../03-python3-babel_2.8.0+dfsg.1-7_all.deb ...\n",
            "Unpacking python3-babel (2.8.0+dfsg.1-7) ...\n",
            "Selecting previously unselected package python3-markupsafe.\n",
            "Preparing to unpack .../04-python3-markupsafe_2.0.1-2build1_amd64.deb ...\n",
            "Unpacking python3-markupsafe (2.0.1-2build1) ...\n",
            "Selecting previously unselected package python3-jinja2.\n",
            "Preparing to unpack .../05-python3-jinja2_3.0.3-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-jinja2 (3.0.3-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-packaging.\n",
            "Preparing to unpack .../06-python3-packaging_21.3-1_all.deb ...\n",
            "Unpacking python3-packaging (21.3-1) ...\n",
            "Selecting previously unselected package python3-resolvelib.\n",
            "Preparing to unpack .../07-python3-resolvelib_0.8.1-1_all.deb ...\n",
            "Unpacking python3-resolvelib (0.8.1-1) ...\n",
            "Selecting previously unselected package ansible-core.\n",
            "Preparing to unpack .../08-ansible-core_2.17.9-1ppa~jammy_all.deb ...\n",
            "Unpacking ansible-core (2.17.9-1ppa~jammy) ...\n",
            "Selecting previously unselected package ansible.\n",
            "Preparing to unpack .../09-ansible_10.7.0-1ppa~jammy_all.deb ...\n",
            "Unpacking ansible (10.7.0-1ppa~jammy) ...\n",
            "Selecting previously unselected package python3-certifi.\n",
            "Preparing to unpack .../10-python3-certifi_2020.6.20-1_all.deb ...\n",
            "Unpacking python3-certifi (2020.6.20-1) ...\n",
            "Selecting previously unselected package python3-chardet.\n",
            "Preparing to unpack .../11-python3-chardet_4.0.0-1_all.deb ...\n",
            "Unpacking python3-chardet (4.0.0-1) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../12-python3-idna_3.3-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-idna (3.3-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-jmespath.\n",
            "Preparing to unpack .../13-python3-jmespath_0.10.0-1_all.deb ...\n",
            "Unpacking python3-jmespath (0.10.0-1) ...\n",
            "Selecting previously unselected package python3-kerberos.\n",
            "Preparing to unpack .../14-python3-kerberos_1.1.14-3.1build5_amd64.deb ...\n",
            "Unpacking python3-kerberos (1.1.14-3.1build5) ...\n",
            "Selecting previously unselected package python3-nacl.\n",
            "Preparing to unpack .../15-python3-nacl_1.5.0-2_amd64.deb ...\n",
            "Unpacking python3-nacl (1.5.0-2) ...\n",
            "Selecting previously unselected package python3-ntlm-auth.\n",
            "Preparing to unpack .../16-python3-ntlm-auth_1.4.0-1_all.deb ...\n",
            "Unpacking python3-ntlm-auth (1.4.0-1) ...\n",
            "Selecting previously unselected package python3-bcrypt.\n",
            "Preparing to unpack .../17-python3-bcrypt_3.2.0-1build1_amd64.deb ...\n",
            "Unpacking python3-bcrypt (3.2.0-1build1) ...\n",
            "Selecting previously unselected package python3-paramiko.\n",
            "Preparing to unpack .../18-python3-paramiko_2.9.3-0ubuntu1.3_all.deb ...\n",
            "Unpacking python3-paramiko (2.9.3-0ubuntu1.3) ...\n",
            "Selecting previously unselected package python3-urllib3.\n",
            "Preparing to unpack .../19-python3-urllib3_1.26.5-1~exp1ubuntu0.2_all.deb ...\n",
            "Unpacking python3-urllib3 (1.26.5-1~exp1ubuntu0.2) ...\n",
            "Selecting previously unselected package python3-requests.\n",
            "Preparing to unpack .../20-python3-requests_2.25.1+dfsg-2ubuntu0.1_all.deb ...\n",
            "Unpacking python3-requests (2.25.1+dfsg-2ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-requests-kerberos.\n",
            "Preparing to unpack .../21-python3-requests-kerberos_0.12.0-2_all.deb ...\n",
            "Unpacking python3-requests-kerberos (0.12.0-2) ...\n",
            "Selecting previously unselected package python3-requests-ntlm.\n",
            "Preparing to unpack .../22-python3-requests-ntlm_1.1.0-1.1_all.deb ...\n",
            "Unpacking python3-requests-ntlm (1.1.0-1.1) ...\n",
            "Selecting previously unselected package python3-xmltodict.\n",
            "Preparing to unpack .../23-python3-xmltodict_0.12.0-2_all.deb ...\n",
            "Unpacking python3-xmltodict (0.12.0-2) ...\n",
            "Selecting previously unselected package python3-winrm.\n",
            "Preparing to unpack .../24-python3-winrm_0.3.0-2_all.deb ...\n",
            "Unpacking python3-winrm (0.3.0-2) ...\n",
            "Selecting previously unselected package sshpass.\n",
            "Preparing to unpack .../25-sshpass_1.09-1_amd64.deb ...\n",
            "Unpacking sshpass (1.09-1) ...\n",
            "Setting up python3-ntlm-auth (1.4.0-1) ...\n",
            "Setting up python3-bcrypt (3.2.0-1build1) ...\n",
            "Setting up python3-resolvelib (0.8.1-1) ...\n",
            "Setting up python3-kerberos (1.1.14-3.1build5) ...\n",
            "Setting up python3-yaml (5.4.1-1ubuntu1) ...\n",
            "Setting up python3-markupsafe (2.0.1-2build1) ...\n",
            "Setting up sshpass (1.09-1) ...\n",
            "Setting up python3-tz (2022.1-1ubuntu0.22.04.1) ...\n",
            "Setting up python-babel-localedata (2.8.0+dfsg.1-7) ...\n",
            "Setting up python3-xmltodict (0.12.0-2) ...\n",
            "Setting up python3-packaging (21.3-1) ...\n",
            "Setting up python3-chardet (4.0.0-1) ...\n",
            "Setting up python3-certifi (2020.6.20-1) ...\n",
            "Setting up python3-jmespath (0.10.0-1) ...\n",
            "Setting up python3-idna (3.3-1ubuntu0.1) ...\n",
            "Setting up python3-urllib3 (1.26.5-1~exp1ubuntu0.2) ...\n",
            "Setting up python3-nacl (1.5.0-2) ...\n",
            "Setting up python3-babel (2.8.0+dfsg.1-7) ...\n",
            "update-alternatives: using /usr/bin/pybabel-python3 to provide /usr/bin/pybabel (pybabel) in auto mode\n",
            "Setting up python3-jinja2 (3.0.3-1ubuntu0.4) ...\n",
            "Setting up python3-requests (2.25.1+dfsg-2ubuntu0.1) ...\n",
            "Setting up python3-requests-kerberos (0.12.0-2) ...\n",
            "Setting up python3-paramiko (2.9.3-0ubuntu1.3) ...\n",
            "Setting up python3-requests-ntlm (1.1.0-1.1) ...\n",
            "Setting up ansible-core (2.17.9-1ppa~jammy) ...\n",
            "Setting up python3-winrm (0.3.0-2) ...\n",
            "Setting up ansible (10.7.0-1ppa~jammy) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "Repository: 'deb [arch=amd64] https://apt.releases.hashicorp.com jammy main'\n",
            "Description:\n",
            "Archive for codename: jammy components: main\n",
            "More info: https://apt.releases.hashicorp.com\n",
            "Adding repository.\n",
            "Press [ENTER] to continue or Ctrl-c to cancel.\n",
            "Adding deb entry to /etc/apt/sources.list.d/archive_uri-https_apt_releases_hashicorp_com-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/archive_uri-https_apt_releases_hashicorp_com-jammy.list\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:3 https://apt.releases.hashicorp.com jammy InRelease [12.9 kB]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://apt.releases.hashicorp.com jammy/main amd64 Packages [212 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/ansible/ansible/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,235 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,682 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,533 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,995 kB]\n",
            "Fetched 9,054 kB in 2s (4,035 kB/s)\n",
            "Reading package lists... Done\n",
            "W: https://apt.releases.hashicorp.com/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://apt.releases.hashicorp.com jammy InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ansible/ansible/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: https://apt.releases.hashicorp.com/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  terraform\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 27.4 MB of archives.\n",
            "After this operation, 89.6 MB of additional disk space will be used.\n",
            "Get:1 https://apt.releases.hashicorp.com jammy/main amd64 terraform amd64 1.11.1-1 [27.4 MB]\n",
            "Fetched 27.4 MB in 0s (60.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package terraform.\n",
            "(Reading database ... 151585 files and directories currently installed.)\n",
            "Preparing to unpack .../terraform_1.11.1-1_amd64.deb ...\n",
            "Unpacking terraform (1.11.1-1) ...\n",
            "Setting up terraform (1.11.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y software-properties-common\n",
        "!sudo apt-add-repository --yes --update ppa:ansible/ansible\n",
        "!sudo apt-get install -y ansible\n",
        "!curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -\n",
        "!sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\"\n",
        "!sudo apt-get update && sudo apt-get install terraform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0xUP7IVf5dt",
        "outputId": "dbf2653e-3973-403b-95ff-03bd8c247dfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You are running on a Google Compute Engine virtual machine.\n",
            "The service credentials associated with this virtual machine\n",
            "will automatically be used by Application Default\n",
            "Credentials, so it is not necessary to use this command.\n",
            "\n",
            "If you decide to proceed anyway, your user credentials may be visible\n",
            "to others with access to this virtual machine. Are you sure you want\n",
            "to authenticate with your personal account?\n",
            "\n",
            "Do you want to continue (Y/n)?  y\n",
            "\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=qWGIGCWv8onkRYEE187ymNCUIN4H55&prompt=consent&token_usage=remote&access_type=offline&code_challenge=juvIDeLBh2PJd4q9FFA9OBbb8NspYr4yddYoxSfEY6s&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AQSTgQGCkbCyc3lrU3dPAc7aYQVwrez8PZPrMif52v9AvidyfHPUhLkOzBuUczwGeYx7WA\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwA5XpHrdPW5"
      },
      "source": [
        "# Atividade 1 - Provisionamento de Infraestrutura Automatizada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRqlNgSQhriH",
        "outputId": "2e39ffd6-0ff8-476b-df4f-28110435dcdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting main.tf\n"
          ]
        }
      ],
      "source": [
        "# Criar um bucket no GCP\n",
        "\n",
        "%%writefile main.tf\n",
        "provider \"google\" {\n",
        "  project = \"absolute-vertex-451423-n7\"\n",
        "  region  = \"us-central1\"\n",
        "}\n",
        "\n",
        "resource \"google_storage_bucket\" \"petadota_imagens\" {\n",
        "  name     = \"petadota-imagens-bucket\"\n",
        "  location = \"US\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzflWYk-flvT",
        "outputId": "a923cea0-542a-4b2e-f758-ba8f2ed360ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting main.tf\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.tf\n",
        "\n",
        "provider \"google\" {\n",
        "  project = \"absolute-vertex-451423-n7\"\n",
        "  region  = \"us-central1\"\n",
        "}\n",
        "\n",
        "resource \"google_storage_bucket\" \"petadota_imagens\" {\n",
        "  name          = \"petadota-imagens-bucket\"\n",
        "  location      = \"US\"\n",
        "  storage_class = \"STANDARD\"  # Alternativas: MULTI_REGIONAL, NEARLINE, COLDLINE, ARCHIVE\n",
        "\n",
        "  # Habilita controle de versões para recuperação de arquivos excluídos\n",
        "  versioning {\n",
        "    enabled = true\n",
        "  }\n",
        "\n",
        "  # Define regras de retenção (Exemplo: 30 dias)\n",
        "  lifecycle_rule {\n",
        "    action {\n",
        "      type = \"Delete\"\n",
        "    }\n",
        "    condition {\n",
        "      age = 30\n",
        "    }\n",
        "  }\n",
        "\n",
        "  # Define acesso público (cuidado com dados sensíveis)\n",
        "  uniform_bucket_level_access = true\n",
        "\n",
        "  labels = {\n",
        "    environment = \"development\"\n",
        "    owner       = \"rodrigo\"\n",
        "  }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5weGykXziMXj",
        "outputId": "0961d474-47ff-4296-cfef-cd9d26e53285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating public/private rsa key pair.\n",
            "Enter file in which to save the key (/root/.ssh/id_rsa): \n",
            "Created directory '/root/.ssh'.\n",
            "Enter passphrase (empty for no passphrase): \n",
            "Enter same passphrase again: \n",
            "Your identification has been saved in /root/.ssh/id_rsa\n",
            "Your public key has been saved in /root/.ssh/id_rsa.pub\n",
            "The key fingerprint is:\n",
            "SHA256:pRQoO6RoKpEEHv6toikHpELwoOM8XGukoYrDyX/3m8w ratolasombra@gmail.com\n",
            "The key's randomart image is:\n",
            "+---[RSA 4096]----+\n",
            "|o.     ..        |\n",
            "|=.. o .  .       |\n",
            "|+B o o  . .      |\n",
            "|*=+o+  . o       |\n",
            "|@o=..o  S        |\n",
            "|B* o.            |\n",
            "|Bo+.             |\n",
            "|*=o  . .o .      |\n",
            "|+o... . .E.      |\n",
            "+----[SHA256]-----+\n"
          ]
        }
      ],
      "source": [
        "!ssh-keygen -t rsa -b 4096 -C \"ratolasombra@gmail.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0FqXkmGiham",
        "outputId": "4a369191-f49f-413f-a64b-5df874acfbe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDhkJhIQX6dHf7zEKfnB5iCNIBZHe3tde7qUAYZHQntL//EvfgaL0oO2nvifVvnVMFyji8JA7x8+zNCoq1mehsrtPPMS97/XuF+DRNLG4VobRvPVzs3x2R/6YmR8whkfvUfdEzOp5V5Ip9NWf+pFpMRbSJrK2JGebBTP+iuf+iLFXIMiHkNz6HDS9VM51M4b7zRMJWFquZA9clN4ZjVNxdcceBJA1PlxsMo+YYvYWt6WNTqa4MvEkYGmGyqrt1I6mOcFCFW5M2BmwTIJfPQObKfXXXTtPhaUsL6IYaizFm8rNZ74hqsS/P4SKEqBuJoaiBl2QZmboULpRjl6R6azWSWr8VwY7oogEG6vjk8PV+Kxg91kS2M67wfChBcuMFYYHdWMaTRv9pKfq6PklJqHRYhrej3TtXdwV3lZP3z0JtzwlWERriZI5RVggp0Zh4J1+v7My4r1YJoOXqE1OLDLUPDpvTzeq1VqegPwvJldyWR+O3e7babUmwGH3ovZoBA7ZV8Tb78Wb8RmYoQgUf+EizbzGXUxT5sX7IRV+ltupFUpg3sLGMz8Nl1ZqTJFXy32M+WfmCHYw7ejxaVJr57RLookFqWaD8y69kLM0827T3fxiqB8guYcpAGSPUWhG+2CaM2gGzDRJt6638+vVMkaGt2bdQlGjHdBEWbaZBw1xPGXQ== ratolasombra@gmail.com\n"
          ]
        }
      ],
      "source": [
        "cat ~/.ssh/id_rsa.pub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP-eYExdh-UM",
        "outputId": "61269861-afd6-41ed-9419-966b6226aa06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Appending to main.tf\n"
          ]
        }
      ],
      "source": [
        "# Provisionar uma máquina virtual Linux\n",
        "\n",
        "%%writefile -a main.tf\n",
        "resource \"google_compute_instance\" \"db_vm\" {\n",
        "  name         = \"petadota-db-vm\"\n",
        "  machine_type = \"e2-medium\"\n",
        "  zone         = \"us-central1-a\"\n",
        "\n",
        "  boot_disk {\n",
        "    initialize_params {\n",
        "      image = \"debian-cloud/debian-11\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  network_interface {\n",
        "    network = \"default\"\n",
        "    access_config {\n",
        "    }\n",
        "  }\n",
        "\n",
        "  metadata = {\n",
        "    ssh-keys = \"ubuntu:ssh-rsa ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDhkJhIQX6dHf7zEKfnB5iCNIBZHe3tde7qUAYZHQntL//EvfgaL0oO2nvifVvnVMFyji8JA7x8+zNCoq1mehsrtPPMS97/XuF+DRNLG4VobRvPVzs3x2R/6YmR8whkfvUfdEzOp5V5Ip9NWf+pFpMRbSJrK2JGebBTP+iuf+iLFXIMiHkNz6HDS9VM51M4b7zRMJWFquZA9clN4ZjVNxdcceBJA1PlxsMo+YYvYWt6WNTqa4MvEkYGmGyqrt1I6mOcFCFW5M2BmwTIJfPQObKfXXXTtPhaUsL6IYaizFm8rNZ74hqsS/P4SKEqBuJoaiBl2QZmboULpRjl6R6azWSWr8VwY7oogEG6vjk8PV+Kxg91kS2M67wfChBcuMFYYHdWMaTRv9pKfq6PklJqHRYhrej3TtXdwV3lZP3z0JtzwlWERriZI5RVggp0Zh4J1+v7My4r1YJoOXqE1OLDLUPDpvTzeq1VqegPwvJldyWR+O3e7babUmwGH3ovZoBA7ZV8Tb78Wb8RmYoQgUf+EizbzGXUxT5sX7IRV+ltupFUpg3sLGMz8Nl1ZqTJFXy32M+WfmCHYw7ejxaVJr57RLookFqWaD8y69kLM0827T3fxiqB8guYcpAGSPUWhG+2CaM2gGzDRJt6638+vVMkaGt2bdQlGjHdBEWbaZBw1xPGXQ== ratolasombra@gmail.com\"\n",
        "  }\n",
        "}\n",
        "\n",
        "output \"vm_ip\" {\n",
        "  value = google_compute_instance.db_vm.network_interface[0].access_config[0].nat_ip\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuEfHFIGtt1n",
        "outputId": "3f293372-29e2-417f-e76f-28a02f4fad2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
            "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
            "- Finding latest version of hashicorp/google...\n",
            "- Installing hashicorp/google v6.25.0...\n",
            "- Installed hashicorp/google v6.25.0 (signed by HashiCorp)\n",
            "Terraform has created a lock file \u001b[1m.terraform.lock.hcl\u001b[0m to record the provider\n",
            "selections it made above. Include this file in your version control repository\n",
            "so that Terraform can guarantee to make the same selections by default when\n",
            "you run \"terraform init\" in the future.\u001b[0m\n",
            "\n",
            "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
            "\u001b[0m\u001b[32m\n",
            "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
            "any changes that are required for your infrastructure. All Terraform commands\n",
            "should now work.\n",
            "\n",
            "If you ever set or change modules or backend configuration for Terraform,\n",
            "rerun this command to reinitialize your working directory. If you forget, other\n",
            "commands will detect it and remind you to do so if necessary.\u001b[0m\n",
            "\n",
            "Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n",
            "  \u001b[32m+\u001b[0m create\u001b[0m\n",
            "\n",
            "Terraform will perform the following actions:\n",
            "\n",
            "\u001b[1m  # google_compute_instance.db_vm\u001b[0m will be created\n",
            "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"google_compute_instance\" \"db_vm\" {\n",
            "      \u001b[32m+\u001b[0m\u001b[0m can_ip_forward       = false\n",
            "      \u001b[32m+\u001b[0m\u001b[0m cpu_platform         = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m creation_timestamp   = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m current_status       = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m deletion_protection  = false\n",
            "      \u001b[32m+\u001b[0m\u001b[0m effective_labels     = {\n",
            "          \u001b[32m+\u001b[0m\u001b[0m \"goog-terraform-provisioned\" = \"true\"\n",
            "        }\n",
            "      \u001b[32m+\u001b[0m\u001b[0m id                   = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m instance_id          = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m label_fingerprint    = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m machine_type         = \"e2-medium\"\n",
            "      \u001b[32m+\u001b[0m\u001b[0m metadata             = {\n",
            "          \u001b[32m+\u001b[0m\u001b[0m \"ssh-keys\" = \"ubuntu:ssh-rsa ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDhkJhIQX6dHf7zEKfnB5iCNIBZHe3tde7qUAYZHQntL//EvfgaL0oO2nvifVvnVMFyji8JA7x8+zNCoq1mehsrtPPMS97/XuF+DRNLG4VobRvPVzs3x2R/6YmR8whkfvUfdEzOp5V5Ip9NWf+pFpMRbSJrK2JGebBTP+iuf+iLFXIMiHkNz6HDS9VM51M4b7zRMJWFquZA9clN4ZjVNxdcceBJA1PlxsMo+YYvYWt6WNTqa4MvEkYGmGyqrt1I6mOcFCFW5M2BmwTIJfPQObKfXXXTtPhaUsL6IYaizFm8rNZ74hqsS/P4SKEqBuJoaiBl2QZmboULpRjl6R6azWSWr8VwY7oogEG6vjk8PV+Kxg91kS2M67wfChBcuMFYYHdWMaTRv9pKfq6PklJqHRYhrej3TtXdwV3lZP3z0JtzwlWERriZI5RVggp0Zh4J1+v7My4r1YJoOXqE1OLDLUPDpvTzeq1VqegPwvJldyWR+O3e7babUmwGH3ovZoBA7ZV8Tb78Wb8RmYoQgUf+EizbzGXUxT5sX7IRV+ltupFUpg3sLGMz8Nl1ZqTJFXy32M+WfmCHYw7ejxaVJr57RLookFqWaD8y69kLM0827T3fxiqB8guYcpAGSPUWhG+2CaM2gGzDRJt6638+vVMkaGt2bdQlGjHdBEWbaZBw1xPGXQ== ratolasombra@gmail.com\"\n",
            "        }\n",
            "      \u001b[32m+\u001b[0m\u001b[0m metadata_fingerprint = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m min_cpu_platform     = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m name                 = \"petadota-db-vm\"\n",
            "      \u001b[32m+\u001b[0m\u001b[0m project              = \"absolute-vertex-451423-n7\"\n",
            "      \u001b[32m+\u001b[0m\u001b[0m self_link            = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m tags_fingerprint     = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m terraform_labels     = {\n",
            "          \u001b[32m+\u001b[0m\u001b[0m \"goog-terraform-provisioned\" = \"true\"\n",
            "        }\n",
            "      \u001b[32m+\u001b[0m\u001b[0m zone                 = \"us-central1-a\"\n",
            "\n",
            "      \u001b[32m+\u001b[0m\u001b[0m boot_disk {\n",
            "          \u001b[32m+\u001b[0m\u001b[0m auto_delete                = true\n",
            "          \u001b[32m+\u001b[0m\u001b[0m device_name                = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m disk_encryption_key_sha256 = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m kms_key_self_link          = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m mode                       = \"READ_WRITE\"\n",
            "          \u001b[32m+\u001b[0m\u001b[0m source                     = (known after apply)\n",
            "\n",
            "          \u001b[32m+\u001b[0m\u001b[0m initialize_params {\n",
            "              \u001b[32m+\u001b[0m\u001b[0m image                  = \"debian-cloud/debian-11\"\n",
            "              \u001b[32m+\u001b[0m\u001b[0m labels                 = (known after apply)\n",
            "              \u001b[32m+\u001b[0m\u001b[0m provisioned_iops       = (known after apply)\n",
            "              \u001b[32m+\u001b[0m\u001b[0m provisioned_throughput = (known after apply)\n",
            "              \u001b[32m+\u001b[0m\u001b[0m resource_policies      = (known after apply)\n",
            "              \u001b[32m+\u001b[0m\u001b[0m size                   = (known after apply)\n",
            "              \u001b[32m+\u001b[0m\u001b[0m type                   = (known after apply)\n",
            "            }\n",
            "        }\n",
            "\n",
            "      \u001b[32m+\u001b[0m\u001b[0m confidential_instance_config (known after apply)\n",
            "\n",
            "      \u001b[32m+\u001b[0m\u001b[0m guest_accelerator (known after apply)\n",
            "\n",
            "      \u001b[32m+\u001b[0m\u001b[0m network_interface {\n",
            "          \u001b[32m+\u001b[0m\u001b[0m internal_ipv6_prefix_length = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m ipv6_access_type            = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m ipv6_address                = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m name                        = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m network                     = \"default\"\n",
            "          \u001b[32m+\u001b[0m\u001b[0m network_attachment          = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m network_ip                  = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m stack_type                  = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m subnetwork                  = (known after apply)\n",
            "          \u001b[32m+\u001b[0m\u001b[0m subnetwork_project          = (known after apply)\n",
            "\n",
            "          \u001b[32m+\u001b[0m\u001b[0m access_config {\n",
            "              \u001b[32m+\u001b[0m\u001b[0m nat_ip       = (known after apply)\n",
            "              \u001b[32m+\u001b[0m\u001b[0m network_tier = (known after apply)\n",
            "            }\n",
            "        }\n",
            "\n",
            "      \u001b[32m+\u001b[0m\u001b[0m reservation_affinity (known after apply)\n",
            "\n",
            "      \u001b[32m+\u001b[0m\u001b[0m scheduling (known after apply)\n",
            "    }\n",
            "\n",
            "\u001b[1m  # google_storage_bucket.petadota_imagens\u001b[0m will be created\n",
            "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"google_storage_bucket\" \"petadota_imagens\" {\n",
            "      \u001b[32m+\u001b[0m\u001b[0m effective_labels            = {\n",
            "          \u001b[32m+\u001b[0m\u001b[0m \"goog-terraform-provisioned\" = \"true\"\n",
            "        }\n",
            "      \u001b[32m+\u001b[0m\u001b[0m force_destroy               = false\n",
            "      \u001b[32m+\u001b[0m\u001b[0m id                          = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m location                    = \"US\"\n",
            "      \u001b[32m+\u001b[0m\u001b[0m name                        = \"petadota-imagens-bucket\"\n",
            "      \u001b[32m+\u001b[0m\u001b[0m project                     = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m project_number              = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m public_access_prevention    = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m rpo                         = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m self_link                   = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m storage_class               = \"STANDARD\"\n",
            "      \u001b[32m+\u001b[0m\u001b[0m terraform_labels            = {\n",
            "          \u001b[32m+\u001b[0m\u001b[0m \"goog-terraform-provisioned\" = \"true\"\n",
            "        }\n",
            "      \u001b[32m+\u001b[0m\u001b[0m uniform_bucket_level_access = (known after apply)\n",
            "      \u001b[32m+\u001b[0m\u001b[0m url                         = (known after apply)\n",
            "\n",
            "      \u001b[32m+\u001b[0m\u001b[0m soft_delete_policy (known after apply)\n",
            "\n",
            "      \u001b[32m+\u001b[0m\u001b[0m versioning (known after apply)\n",
            "\n",
            "      \u001b[32m+\u001b[0m\u001b[0m website (known after apply)\n",
            "    }\n",
            "\n",
            "\u001b[1mPlan:\u001b[0m 2 to add, 0 to change, 0 to destroy.\n",
            "\u001b[0m\n",
            "Changes to Outputs:\n",
            "  \u001b[32m+\u001b[0m\u001b[0m vm_ip = (known after apply)\n",
            "\u001b[0m\u001b[1mgoogle_storage_bucket.petadota_imagens: Creating...\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1mgoogle_compute_instance.db_vm: Creating...\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1mgoogle_storage_bucket.petadota_imagens: Creation complete after 2s [id=petadota-imagens-bucket]\u001b[0m\n",
            "\u001b[0m\u001b[1mgoogle_compute_instance.db_vm: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1mgoogle_compute_instance.db_vm: Creation complete after 17s [id=projects/absolute-vertex-451423-n7/zones/us-central1-a/instances/petadota-db-vm]\u001b[0m\n",
            "\u001b[0m\u001b[1m\u001b[32m\n",
            "Apply complete! Resources: 2 added, 0 changed, 0 destroyed.\n",
            "\u001b[0m\u001b[0m\u001b[1m\u001b[32m\n",
            "Outputs:\n",
            "\n",
            "\u001b[0mvm_ip = \"34.42.74.231\"\n"
          ]
        }
      ],
      "source": [
        "!terraform init\n",
        "!terraform apply -auto-approve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYgpTFWokfnj",
        "outputId": "a622eb11-fd7c-443d-eae4-8ebacb3055c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing setup_mysql.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile setup_mysql.yml\n",
        "- hosts: all\n",
        "  become: yes\n",
        "  tasks:\n",
        "    - name: Install MySQL\n",
        "      apt:\n",
        "        name: mysql-server\n",
        "        state: present\n",
        "\n",
        "    - name: Start MySQL service\n",
        "      service:\n",
        "        name: mysql\n",
        "        state: started\n",
        "        enabled: yes\n",
        "\n",
        "    - name: Create Pet_Adota database\n",
        "      mysql_db:\n",
        "        name: Pet_Adota\n",
        "        state: present\n",
        "\n",
        "    - name: Create animais_disponiveis table\n",
        "      mysql_query:\n",
        "        query: |\n",
        "          CREATE TABLE animais_disponiveis (\n",
        "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "            raca VARCHAR(255) NOT NULL,\n",
        "            url VARCHAR(255) NOT NULL,\n",
        "            tipo ENUM('cachorro', 'gato') NOT NULL\n",
        "          );\n",
        "\n",
        "    - name: Create read-only user\n",
        "      mysql_user:\n",
        "        name: 'read_user'\n",
        "        password: 'readonlypass'\n",
        "        priv: 'Pet_Adota.*:SELECT'\n",
        "        state: present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0B-Hv1gu5ax",
        "outputId": "f2a840aa-0233-4d0a-d2c1-1b27177bb3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
            "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
            "- Reusing previous version of hashicorp/google from the dependency lock file\n",
            "- Using previously-installed hashicorp/google v6.25.0\n",
            "\n",
            "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
            "\u001b[0m\u001b[32m\n",
            "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
            "any changes that are required for your infrastructure. All Terraform commands\n",
            "should now work.\n",
            "\n",
            "If you ever set or change modules or backend configuration for Terraform,\n",
            "rerun this command to reinitialize your working directory. If you forget, other\n",
            "commands will detect it and remind you to do so if necessary.\u001b[0m\n",
            "\u001b[0m\u001b[1mgoogle_storage_bucket.petadota_imagens: Refreshing state... [id=petadota-imagens-bucket]\u001b[0m\n",
            "\u001b[0m\u001b[1mgoogle_compute_instance.db_vm: Refreshing state... [id=projects/absolute-vertex-451423-n7/zones/us-central1-a/instances/petadota-db-vm]\u001b[0m\n",
            "\n",
            "\u001b[0m\u001b[1m\u001b[32mNo changes.\u001b[0m\u001b[1m Your infrastructure matches the configuration.\u001b[0m\n",
            "\n",
            "\u001b[0mTerraform has compared your real infrastructure against your configuration and found no differences, so no changes are needed.\n",
            "\u001b[0m\u001b[1m\u001b[32m\n",
            "Apply complete! Resources: 0 added, 0 changed, 0 destroyed.\n",
            "\u001b[0m\u001b[0m\u001b[1m\u001b[32m\n",
            "Outputs:\n",
            "\n",
            "\u001b[0mvm_ip = \"34.42.74.231\"\n"
          ]
        }
      ],
      "source": [
        "!terraform init\n",
        "!terraform apply -auto-approve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDHKOmlgvTHO",
        "outputId": "7214e530-499b-4e4c-9601-b13d7ccae5b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# 34.31.170.11:22 SSH-2.0-OpenSSH_8.4p1 Debian-5+deb11u4\n",
            "# 34.31.170.11:22 SSH-2.0-OpenSSH_8.4p1 Debian-5+deb11u4\n",
            "# 34.31.170.11:22 SSH-2.0-OpenSSH_8.4p1 Debian-5+deb11u4\n",
            "# 34.31.170.11:22 SSH-2.0-OpenSSH_8.4p1 Debian-5+deb11u4\n",
            "# 34.31.170.11:22 SSH-2.0-OpenSSH_8.4p1 Debian-5+deb11u4\n"
          ]
        }
      ],
      "source": [
        "!ssh-keyscan -H 34.31.170.11 >> ~/.ssh/known_hosts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxasMhGMvfao",
        "outputId": "3c492a84-3757-4c4e-be43-e4552acf046b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/paramiko/pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
            "  \"cipher\": algorithms.TripleDES,\n",
            "/usr/lib/python3/dist-packages/paramiko/transport.py:237: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
            "  \"class\": algorithms.Blowfish,\n",
            "/usr/lib/python3/dist-packages/paramiko/transport.py:261: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
            "  \"class\": algorithms.TripleDES,\n",
            "\u001b[1;35m[WARNING]: Unable to parse /content/34.31.170.11 as an inventory source\u001b[0m\n",
            "\u001b[1;35m[WARNING]: No inventory was parsed, only implicit localhost is available\u001b[0m\n",
            "\u001b[1;35m[WARNING]: provided hosts list is empty, only localhost is available. Note that\u001b[0m\n",
            "\u001b[1;35mthe implicit localhost does not match 'all'\u001b[0m\n",
            "\n",
            "PLAY [all] *********************************************************************\n",
            "\u001b[0;36mskipping: no hosts matched\u001b[0m\n",
            "\n",
            "PLAY RECAP *********************************************************************\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!ansible-playbook -i '34.31.170.11' setup_mysql.yml -u ubuntu --private-key ~/.ssh/id_rsa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeKaB4yRwXLQ"
      },
      "source": [
        "#Atividade 2 - Pipeline de Imagens da API para o Banco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoe6zjHxwoi-",
        "outputId": "8ecda9d2-f8eb-4375-a1c9-ead4be499629"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['https://images.dog.ceo/breeds/pointer-germanlonghair/hans4.jpg',\n",
              "  'https://images.dog.ceo/breeds/terrier-welsh/lucy.jpg',\n",
              "  'https://images.dog.ceo/breeds/terrier-westhighland/n02098286_4876.jpg',\n",
              "  'https://images.dog.ceo/breeds/terrier-border/n02093754_5029.jpg',\n",
              "  'https://images.dog.ceo/breeds/danish-swedish-farmdog/ebba_004.jpg'],\n",
              " ['https://cdn2.thecatapi.com/images/_GVSjXZ4i.jpg',\n",
              "  'https://cdn2.thecatapi.com/images/16k.jpg',\n",
              "  'https://cdn2.thecatapi.com/images/4s9.jpg',\n",
              "  'https://cdn2.thecatapi.com/images/c2p.jpg',\n",
              "  'https://cdn2.thecatapi.com/images/asg.jpg'])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "dog_api_url = \"https://dog.ceo/api/breeds/image/random\"\n",
        "dog_images = []\n",
        "\n",
        "for i in range(10):\n",
        "    response = requests.get(dog_api_url)\n",
        "    dog_images.append(response.json()['message'])\n",
        "\n",
        "cat_api_url = \"https://api.thecatapi.com/v1/images/search\"\n",
        "cat_images = []\n",
        "\n",
        "for i in range(10):\n",
        "    response = requests.get(cat_api_url)\n",
        "    cat_images.append(response.json()[0]['url'])\n",
        "\n",
        "dog_images[:5], cat_images[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qjvWy10kuat",
        "outputId": "8fafa89a-9e17-4d8c-b9a6-531a87bee9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\n",
            "Quota project \"absolute-vertex-451423-n7\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default set-quota-project absolute-vertex-451423-n7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "xOFUH7r7lCdy",
        "outputId": "e7800c03-2656-4ba3-e0da-4e0223388ce9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-20b2a25b-1648-4508-9eb8-e66e09bf6534\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-20b2a25b-1648-4508-9eb8-e66e09bf6534\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving absolute-vertex-451423-n7-54a62dba8bbd.json to absolute-vertex-451423-n7-54a62dba8bbd (2).json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HQelNnwlMnM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/absolute-vertex-451423-n7-54a62dba8bbd.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrgT_xf-lOko"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "client = storage.Client(project=\"absolute-vertex-451423-n7\")\n",
        "bucket = client.get_bucket('petadota-imagens-bucket')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM6M3Hmild16",
        "outputId": "34dba952-2b6f-4737-b609-228fcd599d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cachorro/pointer-germanlonghair/pointer-germanlonghair_01.jpg', 'cachorro/terrier-welsh/terrier-welsh_02.jpg', 'cachorro/terrier-westhighland/terrier-westhighland_03.jpg', 'cachorro/terrier-border/terrier-border_04.jpg', 'cachorro/danish-swedish-farmdog/danish-swedish-farmdog_05.jpg', 'cachorro/spaniel-sussex/spaniel-sussex_06.jpg', 'cachorro/sheepdog-english/sheepdog-english_07.jpg', 'cachorro/pitbull/pitbull_08.jpg', 'cachorro/spaniel-sussex/spaniel-sussex_09.jpg', 'cachorro/bluetick/bluetick_10.jpg'] ['gato/_GVSjXZ4i.jpg/_GVSjXZ4i.jpg_01.jpg', 'gato/16k.jpg/16k.jpg_02.jpg', 'gato/4s9.jpg/4s9.jpg_03.jpg', 'gato/c2p.jpg/c2p.jpg_04.jpg', 'gato/asg.jpg/asg.jpg_05.jpg', 'gato/me56sI74P.jpg/me56sI74P.jpg_06.jpg', 'gato/e0b.jpg/e0b.jpg_07.jpg', 'gato/MTY0NjU4Mg.jpg/MTY0NjU4Mg.jpg_08.jpg', 'gato/a4g.jpg/a4g.jpg_09.jpg', 'gato/9tj.jpg/9tj.jpg_10.jpg']\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import storage\n",
        "import os\n",
        "import requests\n",
        "\n",
        "client = storage.Client()\n",
        "bucket = client.get_bucket('petadota-imagens-bucket')\n",
        "\n",
        "def download_and_store_image(image_url, animal_type, breed, counter):\n",
        "    filename = f\"{breed}_{str(counter).zfill(2)}.jpg\"\n",
        "    file_path = f\"{animal_type}/{breed}/{filename}\"\n",
        "\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "    response = requests.get(image_url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        with open(filename, 'wb') as out_file:\n",
        "            out_file.write(response.content)\n",
        "    else:\n",
        "        raise Exception(f\"Failed to download image. Status code: {response.status_code}\")\n",
        "\n",
        "    blob = bucket.blob(file_path)\n",
        "    blob.upload_from_filename(filename)\n",
        "\n",
        "    os.remove(filename)\n",
        "\n",
        "    return file_path\n",
        "\n",
        "dog_image_paths = []\n",
        "for idx, dog_url in enumerate(dog_images):\n",
        "    breed = dog_url.split('/')[4]\n",
        "    path = download_and_store_image(dog_url, 'cachorro', breed, idx+1)\n",
        "    dog_image_paths.append(path)\n",
        "\n",
        "cat_image_paths = []\n",
        "for idx, cat_url in enumerate(cat_images):\n",
        "    breed = cat_url.split('/')[4]\n",
        "    path = download_and_store_image(cat_url, 'gato', breed, idx+1)\n",
        "    cat_image_paths.append(path)\n",
        "\n",
        "print(dog_image_paths, cat_image_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9rVhBLulo-e"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "def upload_image_to_gcp(image_path, breed, image_name):\n",
        "    storage_client = storage.Client()\n",
        "\n",
        "    bucket_name = \"petadota-imagens-bucket\"\n",
        "    bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "    destination_blob_name = f\"pet-adota-imagens/{'cachorro' if breed != 'gato' else 'gato'}/{breed}/{image_name}\"\n",
        "\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "    blob.upload_from_filename(image_path)\n",
        "    print(f\"Image {image_name} uploaded to GCP at {destination_blob_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QkX6NR2lyrV",
        "outputId": "5a0d5ff4-ef8a-4fd4-c0a3-5b4c6aadeb8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pymysql\n",
        "\n",
        "def register_image_in_db(breed, image_name, image_url, tipo):\n",
        "    connection = pymysql.connect(\n",
        "        host='34.31.170.11',\n",
        "        user='root',\n",
        "        password='',\n",
        "        database='Pet_Adota'\n",
        "    )\n",
        "\n",
        "    cursor = connection.cursor()\n",
        "    query = \"INSERT INTO animais_disponiveis (raca, url, tipo) VALUES (%s, %s, %s)\"\n",
        "    cursor.execute(query, (breed, image_url, tipo))\n",
        "    connection.commit()\n",
        "    cursor.close()\n",
        "    connection.close()\n",
        "    print(f\"Metadata for {image_name} has been registered in the database.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9SAOrHMmqBx",
        "outputId": "94723dcb-6426-4b17-fb3d-9cab81fe038a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: apache-airflow in /usr/local/lib/python3.11/dist-packages (2.10.5)\n",
            "Requirement already satisfied: alembic<2.0,>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.15.1)\n",
            "Requirement already satisfied: argcomplete>=1.10 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.6.0)\n",
            "Requirement already satisfied: asgiref>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.8.1)\n",
            "Requirement already satisfied: attrs>=22.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (25.1.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.9.0)\n",
            "Requirement already satisfied: colorlog>=6.8.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (6.9.0)\n",
            "Requirement already satisfied: configupdater>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.2)\n",
            "Requirement already satisfied: connexion<3.0,>=2.14.2 in /usr/local/lib/python3.11/dist-packages (from connexion[flask]<3.0,>=2.14.2->apache-airflow) (2.14.2)\n",
            "Requirement already satisfied: cron-descriptor>=1.2.24 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.4.5)\n",
            "Requirement already satisfied: croniter>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (6.0.0)\n",
            "Requirement already satisfied: cryptography>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (43.0.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.2.18)\n",
            "Requirement already satisfied: dill>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.3.9)\n",
            "Requirement already satisfied: flask-caching>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.3.1)\n",
            "Requirement already satisfied: flask-session<0.6,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.5.0)\n",
            "Requirement already satisfied: flask-wtf>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.2.2)\n",
            "Requirement already satisfied: flask<2.3,>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.2.5)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2024.10.0)\n",
            "Requirement already satisfied: google-re2>=1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.1.20240702)\n",
            "Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (23.0.0)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.28.1)\n",
            "Requirement already satisfied: importlib_metadata>=6.5 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (8.5.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (4.23.0)\n",
            "Requirement already satisfied: lazy-object-proxy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.10.0)\n",
            "Requirement already satisfied: linkify-it-py>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.0.3)\n",
            "Requirement already satisfied: lockfile>=0.12.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.0.0)\n",
            "Requirement already satisfied: markupsafe>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.0.2)\n",
            "Requirement already satisfied: marshmallow-oneofschema>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.1.1)\n",
            "Requirement already satisfied: mdit-py-plugins>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.4.2)\n",
            "Requirement already satisfied: methodtools>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.4.7)\n",
            "Requirement already satisfied: opentelemetry-api>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.30.0)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (24.2)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.12.1)\n",
            "Requirement already satisfied: pendulum<4.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.0.0)\n",
            "Requirement already satisfied: pluggy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.5.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (5.9.5)\n",
            "Requirement already satisfied: pygments>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.18.0)\n",
            "Requirement already satisfied: pyjwt>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.10.1)\n",
            "Requirement already satisfied: python-daemon>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.8.2)\n",
            "Requirement already satisfied: python-nvd3>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.16.0)\n",
            "Requirement already satisfied: python-slugify>=5.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (8.0.4)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.0.0)\n",
            "Requirement already satisfied: rfc3339-validator>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.1.4)\n",
            "Requirement already satisfied: rich-argparse>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.7.0)\n",
            "Requirement already satisfied: rich>=12.4.4 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (13.9.4)\n",
            "Requirement already satisfied: setproctitle>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.3.5)\n",
            "Requirement already satisfied: sqlalchemy<2.0,>=1.4.36 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.4.54)\n",
            "Requirement already satisfied: sqlalchemy-jsonfield>=1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.9.0)\n",
            "Requirement already satisfied: tenacity!=8.2.0,>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (9.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.5.0)\n",
            "Requirement already satisfied: universal-pathlib!=0.2.4,>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (0.2.6)\n",
            "Requirement already satisfied: werkzeug<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.2.3)\n",
            "Requirement already satisfied: apache-airflow-providers-common-compat in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.5.0)\n",
            "Requirement already satisfied: apache-airflow-providers-common-io in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.5.0)\n",
            "Requirement already satisfied: apache-airflow-providers-common-sql in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.23.0)\n",
            "Requirement already satisfied: apache-airflow-providers-fab>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (1.5.3)\n",
            "Requirement already satisfied: apache-airflow-providers-ftp in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.12.2)\n",
            "Requirement already satisfied: apache-airflow-providers-http in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (5.2.0)\n",
            "Requirement already satisfied: apache-airflow-providers-imap in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (3.8.2)\n",
            "Requirement already satisfied: apache-airflow-providers-smtp in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (2.0.0)\n",
            "Requirement already satisfied: apache-airflow-providers-sqlite in /usr/local/lib/python3.11/dist-packages (from apache-airflow) (4.0.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic<2.0,>=1.13.1->apache-airflow) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic<2.0,>=1.13.1->apache-airflow) (4.12.2)\n",
            "Requirement already satisfied: flask-appbuilder==4.5.3 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-fab>=1.0.2->apache-airflow) (4.5.3)\n",
            "Requirement already satisfied: flask-login>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.6.3)\n",
            "Requirement already satisfied: jmespath>=0.7.0 in /usr/lib/python3/dist-packages (from apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.10.0)\n",
            "Requirement already satisfied: apispec<7,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from apispec[yaml]<7,>=6.0.0->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (6.8.1)\n",
            "Requirement already satisfied: colorama<1,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.4.6)\n",
            "Requirement already satisfied: click<9,>=8 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (8.1.8)\n",
            "Requirement already satisfied: email-validator>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.2.0)\n",
            "Requirement already satisfied: Flask-Babel<3,>=1 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.0.0)\n",
            "Requirement already satisfied: Flask-Limiter<4,>3 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (3.11.0)\n",
            "Requirement already satisfied: Flask-SQLAlchemy<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.5.1)\n",
            "Requirement already satisfied: Flask-JWT-Extended<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (4.7.1)\n",
            "Requirement already satisfied: marshmallow<4,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (3.26.1)\n",
            "Requirement already satisfied: marshmallow-sqlalchemy<0.29.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.28.2)\n",
            "Requirement already satisfied: prison<1.0.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.2.1)\n",
            "Requirement already satisfied: sqlalchemy-utils<1,>=0.32.21 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (0.41.2)\n",
            "Requirement already satisfied: WTForms<4 in /usr/local/lib/python3.11/dist-packages (from flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (3.2.1)\n",
            "Requirement already satisfied: clickclick<21,>=1.2 in /usr/local/lib/python3.11/dist-packages (from connexion<3.0,>=2.14.2->connexion[flask]<3.0,>=2.14.2->apache-airflow) (20.10.2)\n",
            "Requirement already satisfied: PyYAML<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from connexion<3.0,>=2.14.2->connexion[flask]<3.0,>=2.14.2->apache-airflow) (6.0.2)\n",
            "Requirement already satisfied: inflection<0.6,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from connexion<3.0,>=2.14.2->connexion[flask]<3.0,>=2.14.2->apache-airflow) (0.5.1)\n",
            "Requirement already satisfied: pytz>2021.1 in /usr/local/lib/python3.11/dist-packages (from croniter>=2.0.2->apache-airflow) (2025.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=41.0.0->apache-airflow) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->apache-airflow) (1.17.2)\n",
            "Requirement already satisfied: cachelib>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from flask-caching>=2.0.0->apache-airflow) (0.13.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->apache-airflow) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=6.5->apache-airflow) (3.21.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->apache-airflow) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->apache-airflow) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->apache-airflow) (0.23.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py>=2.0.0->apache-airflow) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.1.0->apache-airflow) (0.1.2)\n",
            "Requirement already satisfied: wirerope>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from methodtools>=0.4.7->apache-airflow) (1.0.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.69.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-sdk~=1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (1.30.0)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (5.29.3)\n",
            "Requirement already satisfied: tzdata>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pendulum<4.0,>=2.1.2->apache-airflow) (2025.1)\n",
            "Requirement already satisfied: time-machine>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from pendulum<4.0,>=2.1.2->apache-airflow) (2.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->apache-airflow) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify>=5.0->apache-airflow) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->apache-airflow) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->apache-airflow) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.0,>=1.4.36->apache-airflow) (3.1.1)\n",
            "Requirement already satisfied: sqlparse>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-common-sql->apache-airflow) (0.5.3)\n",
            "Requirement already satisfied: more-itertools>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-common-sql->apache-airflow) (10.6.0)\n",
            "Requirement already satisfied: aiohttp!=3.11.0,>=3.9.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-http->apache-airflow) (3.11.13)\n",
            "Requirement already satisfied: aiosqlite>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-sqlite->apache-airflow) (0.21.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=3.11.0,>=3.9.2->apache-airflow-providers-http->apache-airflow) (1.18.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=41.0.0->apache-airflow) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->apache-airflow) (1.3.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=1.0.5->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.7.0)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.11/dist-packages (from Flask-Babel<3,>=1->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (2.17.0)\n",
            "Requirement already satisfied: limits>=3.13 in /usr/local/lib/python3.11/dist-packages (from Flask-Limiter<4,>3->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (4.2)\n",
            "Requirement already satisfied: ordered-set<5,>4 in /usr/local/lib/python3.11/dist-packages (from Flask-Limiter<4,>3->flask-appbuilder==4.5.3->apache-airflow-providers-fab>=1.0.2->apache-airflow) (4.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk~=1.30.0->opentelemetry-exporter-otlp-proto-grpc==1.30.0->opentelemetry-exporter-otlp>=1.24.0->apache-airflow) (0.51b0)\n"
          ]
        }
      ],
      "source": [
        "!pip install apache-airflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TRnAUSumt0w"
      },
      "outputs": [],
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'retries': 1,\n",
        "    'retry_delay': timedelta(seconds=5),\n",
        "}\n",
        "\n",
        "dag = DAG(\n",
        "    'pipeline_imagens_pet_adota',\n",
        "    default_args=default_args,\n",
        "    description='Pipeline para baixar imagens de cães e gatos, salvar no GCP e registrar no MySQL',\n",
        "    schedule_interval=timedelta(seconds=30),\n",
        "    start_date=datetime(2025, 2, 28),\n",
        "    catchup=False,\n",
        ")\n",
        "\n",
        "def pipeline():\n",
        "    download_dog_images()\n",
        "    download_cat_images()\n",
        "\n",
        "pipeline_task = PythonOperator(\n",
        "    task_id='run_pipeline',\n",
        "    python_callable=pipeline,\n",
        "    dag=dag,\n",
        ")\n",
        "\n",
        "pipeline_task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQDY00p0mzIM",
        "outputId": "61b38d76-0110-4d61-a064-2a4a6f2e7e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Please confirm database initialize (or wait 4 seconds to skip it). Are you sure? [y/N]\n",
            "[\u001b[34m2025-03-11T23:47:57.248+0000\u001b[0m] {\u001b[34mdb.py:\u001b[0m965} INFO\u001b[0m - Log template table does not exist (added in 2.3.0); skipping log template sync.\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.11/dist-packages/flask_limiter/\u001b[0m\u001b[1;33mextension.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m330\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for production use. See: \u001b[0m\u001b[4;33mhttps://flask-limiter.readthedocs.io#configuring-a-storage-backend\u001b[0m\u001b[33m for documentation about configuring the storage backend.\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:58.141+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m969} INFO\u001b[0m - Security DB not found Creating all Models from Base\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.278+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m971} INFO\u001b[0m - Security DB Created\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.308+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1526} INFO\u001b[0m - Inserted Role: \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.314+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m983} \u001b[33mWARNING\u001b[0m - \u001b[33mNo user yet created, use flask fab command to do it.\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.462+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on Passwords\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.502+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Passwords\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.529+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Passwords\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.544+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Passwords\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.597+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on My Password\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.619+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on My Password\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.636+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on My Password\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.653+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on My Password\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.695+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on My Profile\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.717+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on My Profile\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.742+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on My Profile\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.759+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on My Profile\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.877+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan create on Users\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.900+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Users\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.924+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Users\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.945+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Users\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.978+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on Users\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:47:59.995+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Users\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.035+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on Users\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.052+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Users\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.098+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on List Users\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.123+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on List Users\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.161+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Security\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.180+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Security\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.308+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan create on Roles\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.341+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Roles\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.364+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Roles\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.380+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Roles\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.397+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on Roles\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.413+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Roles\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.432+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on Roles\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.448+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Roles\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.487+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on List Roles\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.503+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on List Roles\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.553+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on User Stats Chart\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.569+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on User Stats Chart\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.602+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on User's Statistics\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.617+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on User's Statistics\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.679+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Permissions\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.697+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Permissions\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.792+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Actions\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.818+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Actions\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.938+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on View Menus\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:00.957+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on View Menus\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:01.006+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Resources\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:01.027+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Resources\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:01.101+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Permission Views\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:01.116+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Permission Views\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:01.175+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Permission Pairs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:01.197+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Permission Pairs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:03.008+0000\u001b[0m] {\u001b[34mutils.py:\u001b[0m162} INFO\u001b[0m - NumExpr defaulting to 2 threads.\u001b[0m\n",
            "Password:\n",
            "Repeat for confirmation:\n",
            "[\u001b[34m2025-03-11T23:48:20.518+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1615} INFO\u001b[0m - Added user \u001b[1madmin\u001b[22m\u001b[0m\n",
            "User \"admin\" created with role \"Admin\"\n"
          ]
        }
      ],
      "source": [
        "!airflow users create \\\n",
        "    --username admin \\\n",
        "    --firstname Rodrigo \\\n",
        "    --lastname Charles \\\n",
        "    --role Admin \\\n",
        "    --email ratolasombra@gmail.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk31MpcznF-w",
        "outputId": "4d05183f-f481-4317-8967-c60b03f210aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DB: sqlite:////root/airflow/airflow.db\n",
            "[\u001b[34m2025-03-11T23:48:45.016+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:45.017+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "INFO  [alembic.runtime.migration] Running stamp_revision  -> 5f2621c13b39\n",
            "WARNI [airflow.models.crypto] empty cryptography key - values will not be stored encrypted.\n",
            "Initialization done\n",
            "[\u001b[34m2025-03-11T23:48:48.678+0000\u001b[0m] {\u001b[34mconfiguration.py:\u001b[0m2112} INFO\u001b[0m - Creating new FAB webserver config file in: \u001b[1m/root/airflow/webserver_config.py\u001b[22m\u001b[0m\n",
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
            "Running the Gunicorn Server with:\n",
            "Workers: 4 sync\n",
            "Host: 0.0.0.0:8081\n",
            "Timeout: 120\n",
            "Logfiles: - -\n",
            "Access Logformat: \n",
            "=================================================================\n",
            "\u001b[1;33m/usr/local/lib/python3.11/dist-packages/flask_limiter/\u001b[0m\u001b[1;33mextension.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m330\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for production use. See: \u001b[0m\u001b[4;33mhttps://flask-limiter.readthedocs.io#configuring-a-storage-backend\u001b[0m\u001b[33m for documentation about configuring the storage backend.\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.489+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan create on DAG Runs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.505+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on DAG Runs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.522+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on DAG Runs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.537+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Runs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.552+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on DAG Runs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.566+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on DAG Runs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.581+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on DAG Runs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.596+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on DAG Runs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.610+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on DAG Runs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.624+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAG Runs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.656+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Browse\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.669+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Browse\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.713+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Jobs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.731+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Jobs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.748+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Jobs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.763+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Jobs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.812+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Audit Logs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.828+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Audit Logs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.843+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Audit Logs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.859+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Audit Logs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.907+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan create on Variables\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.921+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Variables\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.935+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Variables\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.948+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Variables\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.963+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on Variables\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.977+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Variables\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:51.992+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on Variables\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.007+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Variables\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.022+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Variables\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.036+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Variables\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.071+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Admin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.087+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Admin\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.134+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan create on Task Instances\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.150+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Task Instances\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.166+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Task Instances\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.181+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Task Instances\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.197+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on Task Instances\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.212+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Task Instances\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.228+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on Task Instances\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.242+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Task Instances\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.258+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Task Instances\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.273+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Task Instances\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.325+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Task Reschedules\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.339+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Task Reschedules\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.354+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Task Reschedules\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.370+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Task Reschedules\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.424+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Triggers\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.440+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Triggers\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.456+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Triggers\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.472+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Triggers\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.510+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Configurations\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.526+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Configurations\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.542+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Configurations\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.558+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Configurations\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.609+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan create on Connections\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.625+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Connections\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.641+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Connections\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.657+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Connections\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.673+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on Connections\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.689+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Connections\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.704+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on Connections\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.722+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Connections\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.739+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Connections\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.755+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Connections\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.811+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on SLA Misses\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.827+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on SLA Misses\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.843+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on SLA Misses\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.859+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on SLA Misses\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.874+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on SLA Misses\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.889+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on SLA Misses\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.905+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on SLA Misses\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.920+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on SLA Misses\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.968+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Plugins\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:52.985+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Plugins\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.003+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Plugins\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.019+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Plugins\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.064+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Providers\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.083+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Providers\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.100+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Providers\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.118+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Providers\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.185+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan create on Pools\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.201+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Pools\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.222+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Pools\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.239+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Pools\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.256+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on Pools\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.273+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Pools\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.288+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on Pools\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.304+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Pools\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.322+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Pools\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.338+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Pools\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.403+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on XComs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.420+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on XComs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.437+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on XComs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.453+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on XComs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.469+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on XComs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.486+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on XComs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.551+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on DAG Dependencies\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.569+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAG Dependencies\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.656+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on DAGs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.673+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAGs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.706+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Cluster Activity\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.726+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Cluster Activity\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.756+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Datasets\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.775+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Datasets\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.811+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Documentation\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.830+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Documentation\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.861+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mmenu access on Docs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:53.878+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Docs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:54.497+0000\u001b[0m] {\u001b[34mutils.py:\u001b[0m162} INFO\u001b[0m - NumExpr defaulting to 2 threads.\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:55.914+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan edit on DAGs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:55.932+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on DAGs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:55.950+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on DAGs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:55.975+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1526} INFO\u001b[0m - Inserted Role: \u001b[1mPublic\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:55.989+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1526} INFO\u001b[0m - Inserted Role: \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.006+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAGs\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.025+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on DAG Dependencies\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.038+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Dependencies\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.065+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on DAG Code\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.078+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Code\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.093+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Runs\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.109+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Datasets\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.124+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Datasets\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.143+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Cluster Activity\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.156+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Cluster Activity\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.169+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Pools\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.198+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on ImportError\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.212+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on ImportError\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.239+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on DAG Warnings\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.253+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Warnings\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.268+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Jobs\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.282+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on My Password\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.295+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on My Password\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.308+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on My Profile\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.321+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on My Profile\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.334+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on SLA Misses\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.349+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Task Instances\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.377+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Task Logs\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.390+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Task Logs\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.403+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on XComs\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.430+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan read on Website\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.444+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Website\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.457+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Browse\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.472+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAGs\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.485+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAG Dependencies\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.499+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAG Runs\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.512+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Datasets\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.525+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Cluster Activity\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.540+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Documentation\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.555+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Docs\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.569+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Jobs\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.583+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on SLA Misses\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.596+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Task Instances\u001b[22m to role \u001b[1mViewer\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.610+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1526} INFO\u001b[0m - Inserted Role: \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.624+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAGs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.641+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Dependencies\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.657+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Code\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.670+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Runs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.686+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Datasets\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.701+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Cluster Activity\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.714+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Pools\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.730+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on ImportError\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.746+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Warnings\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.759+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Jobs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.772+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on My Password\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.786+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on My Password\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.801+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on My Profile\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.814+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on My Profile\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.828+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on SLA Misses\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.841+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Task Instances\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.858+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Task Logs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.870+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on XComs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.885+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Website\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.898+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Browse\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.912+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAGs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.924+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAG Dependencies\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.935+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAG Runs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.949+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Datasets\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.963+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Cluster Activity\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.976+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Documentation\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:56.989+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Docs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.003+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Jobs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.016+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on SLA Misses\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.030+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Task Instances\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.045+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on DAGs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.059+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on DAGs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.073+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Task Instances\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.086+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Task Instances\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.100+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Task Instances\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.113+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on DAG Runs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.127+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on DAG Runs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.140+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on DAG Runs\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.160+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan create on Datasets\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.175+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Datasets\u001b[22m to role \u001b[1mUser\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.189+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1526} INFO\u001b[0m - Inserted Role: \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.204+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAGs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.220+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Dependencies\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.236+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Code\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.250+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Runs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.265+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Datasets\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.281+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Cluster Activity\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.295+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Pools\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.311+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on ImportError\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.326+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Warnings\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.340+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Jobs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.354+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on My Password\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.368+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on My Password\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.382+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on My Profile\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.397+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on My Profile\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.411+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on SLA Misses\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.425+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Task Instances\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.440+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Task Logs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.454+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on XComs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.471+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Website\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.485+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Browse\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.499+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAGs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.513+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAG Dependencies\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.527+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on DAG Runs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.541+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Datasets\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.555+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Cluster Activity\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.569+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Documentation\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.583+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Docs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.597+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Jobs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.610+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on SLA Misses\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.624+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Task Instances\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.637+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on DAGs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.651+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on DAGs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.667+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Task Instances\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.681+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Task Instances\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.694+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Task Instances\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.707+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on DAG Runs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.720+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on DAG Runs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.734+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on DAG Runs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.750+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Datasets\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.763+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Configurations\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.776+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Admin\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.790+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Configurations\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.804+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Connections\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.818+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Pools\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.832+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Plugins\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.846+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Variables\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.859+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on Providers\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.872+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mmenu access on XComs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.885+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Connections\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.898+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Connections\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.911+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Connections\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.926+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Connections\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.939+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Pools\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.952+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Pools\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.965+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Pools\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.978+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Plugins\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:57.991+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Providers\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.004+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Variables\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.018+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Variables\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.031+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on Variables\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.044+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Variables\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.057+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on XComs\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.076+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1930} INFO\u001b[0m - Created Permission View: \u001b[1mcan delete on Datasets\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.090+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Datasets\u001b[22m to role \u001b[1mOp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.105+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAGs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.121+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Dependencies\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.138+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Code\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.153+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Datasets\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.171+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Cluster Activity\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.187+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on ImportError\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.203+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on DAG Warnings\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.218+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Task Logs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.235+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan read on Website\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.249+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan edit on DAGs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.263+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on DAGs\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.280+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan create on Datasets\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[\u001b[34m2025-03-11T23:48:58.296+0000\u001b[0m] {\u001b[34moverride.py:\u001b[0m1981} INFO\u001b[0m - Added Permission \u001b[1mcan delete on Datasets\u001b[22m to role \u001b[1mAdmin\u001b[22m\u001b[0m\n",
            "[2025-03-11 23:48:58 +0000] [19238] [INFO] Starting gunicorn 23.0.0\n",
            "[2025-03-11 23:48:58 +0000] [19238] [INFO] Listening at: http://0.0.0.0:8081 (19238)\n",
            "[2025-03-11 23:48:58 +0000] [19238] [INFO] Using worker: sync\n",
            "[2025-03-11 23:48:58 +0000] [19285] [INFO] Booting worker with pid: 19285\n",
            "[2025-03-11 23:48:58 +0000] [19286] [INFO] Booting worker with pid: 19286\n",
            "[2025-03-11 23:48:58 +0000] [19287] [INFO] Booting worker with pid: 19287\n",
            "[2025-03-11 23:48:58 +0000] [19288] [INFO] Booting worker with pid: 19288\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!airflow db init\n",
        "!airflow webserver -p 8081\n",
        "!airflow scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY7cgeTl1sHV"
      },
      "source": [
        "#Atividade 3 - Processamento de Interações de Usuários em Tempo Real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1AdmA-r1w-M",
        "outputId": "733a1275-bfc0-47f4-a585-9823eeacf805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-19 13:40:05--  https://archive.apache.org/dist/kafka/3.6.1/kafka_2.13-3.6.1.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113466638 (108M) [application/x-gzip]\n",
            "Saving to: ‘kafka_2.13-3.6.1.tgz’\n",
            "\n",
            "kafka_2.13-3.6.1.tg 100%[===================>] 108.21M  2.63MB/s    in 57s     \n",
            "\n",
            "2025-03-19 13:41:02 (1.91 MB/s) - ‘kafka_2.13-3.6.1.tgz’ saved [113466638/113466638]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.apache.org/dist/kafka/3.6.1/kafka_2.13-3.6.1.tgz\n",
        "!tar -xzf kafka_2.13-3.6.1.tgz\n",
        "!mv kafka_2.13-3.6.1 kafka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NEW1nejK9Oti"
      },
      "outputs": [],
      "source": [
        "!kafka/bin/zookeeper-server-start.sh -daemon kafka/config/zookeeper.properties\n",
        "!kafka/bin/kafka-server-start.sh -daemon kafka/config/server.properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG0A-nwk9QfH",
        "outputId": "a574ccf6-7144-49be-c07b-1c587a83a132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.\n",
            "[2025-03-19 13:41:12,480] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)\n",
            "[2025-03-19 13:41:12,555] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)\n",
            "[2025-03-19 13:41:12,657] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)\n",
            "[2025-03-19 13:41:12,859] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)\n",
            "[2025-03-19 13:41:13,265] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)\n",
            "[2025-03-19 13:41:14,170] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)\n",
            "[2025-03-19 13:41:15,177] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)\n",
            "Created topic interacoes_animais.\n"
          ]
        }
      ],
      "source": [
        "!kafka/bin/kafka-topics.sh --create --topic interacoes_animais --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1WKftsK9Y7Z",
        "outputId": "1631cf2e-aec3-4187-ca5f-5b8349a8dde5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kafka-python in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
            "Evento publicado: {'usuario_id': 999, 'raca': 'ragdoll', 'tipo': 'gato', 'timestamp': 1742392329}\n",
            "Evento publicado: {'usuario_id': 927, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392330}\n",
            "Evento publicado: {'usuario_id': 761, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392331}\n",
            "Evento publicado: {'usuario_id': 822, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392332}\n",
            "Evento publicado: {'usuario_id': 427, 'raca': 'poodle', 'tipo': 'cachorro', 'timestamp': 1742392333}\n",
            "Evento publicado: {'usuario_id': 607, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392334}\n",
            "Evento publicado: {'usuario_id': 5, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392335}\n",
            "Evento publicado: {'usuario_id': 18, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392336}\n",
            "Evento publicado: {'usuario_id': 210, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392337}\n",
            "Evento publicado: {'usuario_id': 295, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392338}\n",
            "Evento publicado: {'usuario_id': 841, 'raca': 'ragdoll', 'tipo': 'gato', 'timestamp': 1742392339}\n",
            "Evento publicado: {'usuario_id': 407, 'raca': 'ragdoll', 'tipo': 'gato', 'timestamp': 1742392340}\n",
            "Evento publicado: {'usuario_id': 756, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392341}\n",
            "Evento publicado: {'usuario_id': 401, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392342}\n",
            "Evento publicado: {'usuario_id': 653, 'raca': 'SRD', 'tipo': 'cachorro', 'timestamp': 1742392343}\n",
            "Evento publicado: {'usuario_id': 209, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392344}\n",
            "Evento publicado: {'usuario_id': 420, 'raca': 'poodle', 'tipo': 'cachorro', 'timestamp': 1742392345}\n",
            "Evento publicado: {'usuario_id': 573, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392346}\n",
            "Evento publicado: {'usuario_id': 782, 'raca': 'poodle', 'tipo': 'cachorro', 'timestamp': 1742392347}\n",
            "Evento publicado: {'usuario_id': 22, 'raca': 'SRD', 'tipo': 'cachorro', 'timestamp': 1742392348}\n",
            "Evento publicado: {'usuario_id': 514, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392349}\n",
            "Evento publicado: {'usuario_id': 997, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392350}\n",
            "Evento publicado: {'usuario_id': 958, 'raca': 'SRD', 'tipo': 'cachorro', 'timestamp': 1742392351}\n",
            "Evento publicado: {'usuario_id': 823, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392352}\n",
            "Evento publicado: {'usuario_id': 312, 'raca': 'ragdoll', 'tipo': 'gato', 'timestamp': 1742392353}\n",
            "Evento publicado: {'usuario_id': 178, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392354}\n",
            "Evento publicado: {'usuario_id': 962, 'raca': 'SRD', 'tipo': 'cachorro', 'timestamp': 1742392355}\n",
            "Evento publicado: {'usuario_id': 182, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392356}\n",
            "Evento publicado: {'usuario_id': 554, 'raca': 'ragdoll', 'tipo': 'gato', 'timestamp': 1742392357}\n",
            "Evento publicado: {'usuario_id': 191, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392358}\n",
            "Evento publicado: {'usuario_id': 64, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392359}\n",
            "Evento publicado: {'usuario_id': 615, 'raca': 'siames', 'tipo': 'gato', 'timestamp': 1742392360}\n",
            "Evento publicado: {'usuario_id': 265, 'raca': 'SRD', 'tipo': 'cachorro', 'timestamp': 1742392361}\n",
            "Evento publicado: {'usuario_id': 713, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392362}\n",
            "Evento publicado: {'usuario_id': 418, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392363}\n",
            "Evento publicado: {'usuario_id': 8, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392364}\n",
            "Evento publicado: {'usuario_id': 62, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392365}\n",
            "Evento publicado: {'usuario_id': 591, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392366}\n",
            "Evento publicado: {'usuario_id': 329, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392367}\n",
            "Evento publicado: {'usuario_id': 906, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392368}\n",
            "Evento publicado: {'usuario_id': 626, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392369}\n",
            "Evento publicado: {'usuario_id': 221, 'raca': 'poodle', 'tipo': 'cachorro', 'timestamp': 1742392370}\n",
            "Evento publicado: {'usuario_id': 241, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392371}\n",
            "Evento publicado: {'usuario_id': 722, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392372}\n",
            "Evento publicado: {'usuario_id': 102, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392373}\n",
            "Evento publicado: {'usuario_id': 279, 'raca': 'siames', 'tipo': 'gato', 'timestamp': 1742392374}\n",
            "Evento publicado: {'usuario_id': 348, 'raca': 'siames', 'tipo': 'gato', 'timestamp': 1742392375}\n",
            "Evento publicado: {'usuario_id': 726, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392376}\n",
            "Evento publicado: {'usuario_id': 248, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392377}\n",
            "Evento publicado: {'usuario_id': 890, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392378}\n",
            "Evento publicado: {'usuario_id': 99, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392379}\n",
            "Evento publicado: {'usuario_id': 630, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392380}\n",
            "Evento publicado: {'usuario_id': 800, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392381}\n",
            "Evento publicado: {'usuario_id': 907, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392382}\n",
            "Evento publicado: {'usuario_id': 411, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392383}\n",
            "Evento publicado: {'usuario_id': 900, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392384}\n",
            "Evento publicado: {'usuario_id': 646, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392385}\n",
            "Evento publicado: {'usuario_id': 480, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392386}\n",
            "Evento publicado: {'usuario_id': 857, 'raca': 'siames', 'tipo': 'gato', 'timestamp': 1742392387}\n",
            "Evento publicado: {'usuario_id': 708, 'raca': 'beagle', 'tipo': 'cachorro', 'timestamp': 1742392388}\n",
            "Evento publicado: {'usuario_id': 83, 'raca': 'poodle', 'tipo': 'cachorro', 'timestamp': 1742392389}\n",
            "Evento publicado: {'usuario_id': 188, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392390}\n",
            "Evento publicado: {'usuario_id': 904, 'raca': 'SRD', 'tipo': 'cachorro', 'timestamp': 1742392391}\n",
            "Evento publicado: {'usuario_id': 387, 'raca': 'beagle', 'tipo': 'cachorro', 'timestamp': 1742392392}\n",
            "Evento publicado: {'usuario_id': 280, 'raca': 'SRD', 'tipo': 'cachorro', 'timestamp': 1742392393}\n",
            "Evento publicado: {'usuario_id': 939, 'raca': 'siames', 'tipo': 'gato', 'timestamp': 1742392394}\n",
            "Evento publicado: {'usuario_id': 518, 'raca': 'siames', 'tipo': 'gato', 'timestamp': 1742392395}\n",
            "Evento publicado: {'usuario_id': 387, 'raca': 'siames', 'tipo': 'gato', 'timestamp': 1742392396}\n",
            "Evento publicado: {'usuario_id': 714, 'raca': 'siames', 'tipo': 'gato', 'timestamp': 1742392397}\n",
            "Evento publicado: {'usuario_id': 762, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392398}\n",
            "Evento publicado: {'usuario_id': 985, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392399}\n",
            "Evento publicado: {'usuario_id': 89, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392400}\n",
            "Evento publicado: {'usuario_id': 261, 'raca': 'poodle', 'tipo': 'cachorro', 'timestamp': 1742392401}\n",
            "Evento publicado: {'usuario_id': 478, 'raca': 'SRD', 'tipo': 'cachorro', 'timestamp': 1742392402}\n",
            "Evento publicado: {'usuario_id': 791, 'raca': 'beagle', 'tipo': 'cachorro', 'timestamp': 1742392403}\n",
            "Evento publicado: {'usuario_id': 522, 'raca': 'siames', 'tipo': 'gato', 'timestamp': 1742392404}\n",
            "Evento publicado: {'usuario_id': 485, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392405}\n",
            "Evento publicado: {'usuario_id': 883, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392406}\n",
            "Evento publicado: {'usuario_id': 981, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392407}\n",
            "Evento publicado: {'usuario_id': 146, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392408}\n",
            "Evento publicado: {'usuario_id': 542, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392409}\n",
            "Evento publicado: {'usuario_id': 585, 'raca': 'ragdoll', 'tipo': 'gato', 'timestamp': 1742392410}\n",
            "Evento publicado: {'usuario_id': 688, 'raca': 'ragdoll', 'tipo': 'gato', 'timestamp': 1742392411}\n",
            "Evento publicado: {'usuario_id': 165, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392412}\n",
            "Evento publicado: {'usuario_id': 968, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392413}\n",
            "Evento publicado: {'usuario_id': 78, 'raca': 'beagle', 'tipo': 'cachorro', 'timestamp': 1742392414}\n",
            "Evento publicado: {'usuario_id': 997, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392415}\n",
            "Evento publicado: {'usuario_id': 463, 'raca': 'beagle', 'tipo': 'cachorro', 'timestamp': 1742392416}\n",
            "Evento publicado: {'usuario_id': 987, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392417}\n",
            "Evento publicado: {'usuario_id': 316, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392418}\n",
            "Evento publicado: {'usuario_id': 417, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392419}\n",
            "Evento publicado: {'usuario_id': 207, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392420}\n",
            "Evento publicado: {'usuario_id': 5, 'raca': 'bengal', 'tipo': 'gato', 'timestamp': 1742392421}\n",
            "Evento publicado: {'usuario_id': 954, 'raca': 'poodle', 'tipo': 'cachorro', 'timestamp': 1742392422}\n",
            "Evento publicado: {'usuario_id': 949, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392423}\n",
            "Evento publicado: {'usuario_id': 318, 'raca': 'husky', 'tipo': 'cachorro', 'timestamp': 1742392424}\n",
            "Evento publicado: {'usuario_id': 961, 'raca': 'sphynx', 'tipo': 'gato', 'timestamp': 1742392425}\n",
            "Evento publicado: {'usuario_id': 500, 'raca': 'labrador', 'tipo': 'cachorro', 'timestamp': 1742392426}\n",
            "Evento publicado: {'usuario_id': 60, 'raca': 'persa', 'tipo': 'gato', 'timestamp': 1742392427}\n",
            "Evento publicado: {'usuario_id': 694, 'raca': 'SRD', 'tipo': 'cachorro', 'timestamp': 1742392428}\n"
          ]
        }
      ],
      "source": [
        "!pip install kafka-python\n",
        "\n",
        "from kafka import KafkaProducer\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "\n",
        "producer = KafkaProducer(\n",
        "    bootstrap_servers=['localhost:9092'],\n",
        "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
        ")\n",
        "\n",
        "racas_cachorro = [\"labrador\", \"SRD\", \"poodle\", \"beagle\", \"husky\"]\n",
        "racas_gato = [\"siames\", \"persa\", \"sphynx\", \"ragdoll\", \"bengal\"]\n",
        "\n",
        "def gerar_evento():\n",
        "    usuario_id = random.randint(1, 1000)\n",
        "    tipo = random.choice([\"cachorro\", \"gato\"])\n",
        "    raca = random.choice(racas_cachorro if tipo == \"cachorro\" else racas_gato)\n",
        "    timestamp = int(time.time())\n",
        "\n",
        "    evento = {\n",
        "        \"usuario_id\": usuario_id,\n",
        "        \"raca\": raca,\n",
        "        \"tipo\": tipo,\n",
        "        \"timestamp\": timestamp\n",
        "    }\n",
        "\n",
        "    return evento\n",
        "\n",
        "for _ in range(100):\n",
        "    evento = gerar_evento()\n",
        "    producer.send('interacoes_animais', evento)\n",
        "    print(f\"Evento publicado: {evento}\")\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zeu4EGsbAj10",
        "outputId": "5a9c5ea0-8542-4fb4-d1a1-bd2df3ade12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `\"kafka.bootstrap.servers\",'\n",
            "/bin/bash: -c: line 1: `.option(\"kafka.bootstrap.servers\", \"VM_EXTERNAL_IP:9092\")'\n"
          ]
        }
      ],
      "source": [
        "!.option(\"kafka.bootstrap.servers\", \"VM_EXTERNAL_IP:9092\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install kafka-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCQTMJ8sstXz",
        "outputId": "81af6afe-008f-4e30-f369-6e5e50e6aae1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: kafka-python in /usr/local/lib/python3.11/dist-packages (2.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType\n",
        "\n",
        "# Criando a sessão do Spark com suporte ao Kafka\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MonitoramentoAdocoes\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Definir o schema que esperamos dos eventos Kafka\n",
        "schema = StructType([\n",
        "    StructField(\"usuario_id\", IntegerType(), True),\n",
        "    StructField(\"raca\", StringType(), True),\n",
        "    StructField(\"tipo\", StringType(), True),\n",
        "    StructField(\"timestamp\", LongType(), True)\n",
        "])\n",
        "\n",
        "# Consumir dados do Kafka\n",
        "df_kafka = spark.readStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "    .option(\"subscribe\", \"interacoes_animais\") \\\n",
        "    .load()\n",
        "\n",
        "# Converter o valor do Kafka de bytes para String\n",
        "df_json = df_kafka.selectExpr(\"CAST(value AS STRING)\")\n",
        "\n",
        "# Parse do JSON para o formato estruturado\n",
        "df_parsed = df_json.selectExpr(\"json_tuple(value, 'usuario_id', 'raca', 'tipo', 'timestamp') as (usuario_id, raca, tipo, timestamp)\")\n",
        "\n",
        "# Alterar os tipos de dados conforme o esperado\n",
        "df_final = df_parsed.select(\n",
        "    col(\"usuario_id\").cast(IntegerType()),\n",
        "    col(\"raca\"),\n",
        "    col(\"tipo\"),\n",
        "    col(\"timestamp\").cast(LongType())\n",
        ")\n",
        "\n",
        "# Agora você pode realizar operações como groupBy\n",
        "tendencias = df_final.groupBy(\"raca\", \"tipo\").count()\n",
        "\n",
        "# Exibir o resultado para cada micro-batch\n",
        "query = tendencias.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"console\") \\\n",
        "    .start()\n",
        "\n",
        "# Espera até que a consulta termine (se necessário)\n",
        "query.awaitTermination()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "Uda9mcL1sUzq",
        "outputId": "ca191bd7-0dd3-4162-e83b-c5183ee81e04"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: Only one SparkContext should be running in this JVM (see SPARK-2243).The currently running SparkContext was created at:\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n\tat org.apache.spark.SparkContext$.$anonfun$assertNoOtherContextIsRunning$2(SparkContext.scala:2840)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2837)\n\tat org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2927)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:99)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1f3ec9b7a81f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MonitoramentoAdocoes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Definir o schema que esperamos dos eventos Kafka\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             self._do_init(\n\u001b[0m\u001b[1;32m    204\u001b[0m                 \u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mappName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# Create the Java SparkContext through Py4J\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;31m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_initialize_context\u001b[0;34m(self, jconf)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \"\"\"\n\u001b[1;32m    420\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJavaSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1588\u001b[0m             answer, self._gateway_client, None, self._fqn)\n\u001b[1;32m   1589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: Only one SparkContext should be running in this JVM (see SPARK-2243).The currently running SparkContext was created at:\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n\tat org.apache.spark.SparkContext$.$anonfun$assertNoOtherContextIsRunning$2(SparkContext.scala:2840)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2837)\n\tat org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2927)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:99)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "Qk50VGwyAl9_",
        "outputId": "bf29695e-d17d-44de-983a-c53976450bac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: Only one SparkContext should be running in this JVM (see SPARK-2243).The currently running SparkContext was created at:\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n\tat org.apache.spark.SparkContext$.$anonfun$assertNoOtherContextIsRunning$2(SparkContext.scala:2840)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2837)\n\tat org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2927)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:99)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-adc7c0e6750d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Criando a sessão do Spark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MonitoramentoAdocoes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Dados de entrada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             self._do_init(\n\u001b[0m\u001b[1;32m    204\u001b[0m                 \u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mappName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# Create the Java SparkContext through Py4J\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;31m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_initialize_context\u001b[0;34m(self, jconf)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \"\"\"\n\u001b[1;32m    420\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJavaSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1588\u001b[0m             answer, self._gateway_client, None, self._fqn)\n\u001b[1;32m   1589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: org.apache.spark.SparkException: Only one SparkContext should be running in this JVM (see SPARK-2243).The currently running SparkContext was created at:\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n\tat org.apache.spark.SparkContext$.$anonfun$assertNoOtherContextIsRunning$2(SparkContext.scala:2840)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2837)\n\tat org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2927)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:99)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType\n",
        "\n",
        "# Criando a sessão do Spark\n",
        "spark = SparkSession.builder.appName(\"MonitoramentoAdocoes\").getOrCreate()\n",
        "\n",
        "# Dados de entrada\n",
        "data = [\n",
        "    (1, \"Labrador\", \"cachorro\", 1700000000),\n",
        "    (2, \"Persa\", \"gato\", 1700000020),\n",
        "    (3, \"Labrador\", \"cachorro\", 1700000050),\n",
        "]\n",
        "\n",
        "# Definindo o schema, alterando o tipo de timestamp para LongType\n",
        "schema = StructType([\n",
        "    StructField(\"usuario_id\", IntegerType()),\n",
        "    StructField(\"raca\", StringType()),\n",
        "    StructField(\"tipo\", StringType()),\n",
        "    StructField(\"timestamp\", LongType())  # Alterando para LongType\n",
        "])\n",
        "\n",
        "# Criando o DataFrame\n",
        "df_json = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Agrupando por raça e tipo e contando as visualizações\n",
        "tendencias = df_json.groupBy(\"raca\", \"tipo\").agg(count(\"*\").alias(\"visualizacoes\"))\n",
        "\n",
        "# Exibindo o resultado\n",
        "tendencias.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "yX9ef7e2cDPB",
        "outputId": "43134425-ff1a-4986-835d-aaceadd88e74"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_json' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-da566585a497>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_filtrado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"current_timestamp() - INTERVAL 1 MINUTE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_filtrado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_json' is not defined"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, expr\n",
        "df_filtrado = df_json.filter(col(\"timestamp\") >= expr(\"current_timestamp() - INTERVAL 1 MINUTE\"))\n",
        "\n",
        "df_filtrado.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p02ow2eUdtcu"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"SalvarEstatisticasMySQL\") \\\n",
        "    .config(\"spark.jars.packages\", \"mysql:mysql-connector-java:8.0.33\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNY0NmG7eiid",
        "outputId": "be6cf15a-4a4d-4a92-ea58-f42ecf24292e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: telnet: command not found\n"
          ]
        }
      ],
      "source": [
        "!telnet 34.31.170.11 3306"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxlV77gKfu-G",
        "outputId": "4beea481-0f22-40f3-f572-ccf474a261ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.31.160.175"
          ]
        }
      ],
      "source": [
        "!curl ifconfig.me"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D1Tj1wVg99M",
        "outputId": "4c23cc63-2cba-4529-ab3f-bfdf5d64a2b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sudo: ufw: command not found\n",
            "sudo: ufw: command not found\n"
          ]
        }
      ],
      "source": [
        "!sudo ufw allow 3306/tcp\n",
        "!sudo ufw reload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "myILm5OHja8e",
        "outputId": "887c01ee-7781-4667-eef5-f192faa0eeda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (1.4.54)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Collecting cloud-sql-python-connector\n",
            "  Downloading cloud_sql_python_connector-1.17.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting aiofiles (from cloud-sql-python-connector)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from cloud-sql-python-connector) (3.11.13)\n",
            "Requirement already satisfied: cryptography>=42.0.0 in /usr/local/lib/python3.11/dist-packages (from cloud-sql-python-connector) (43.0.3)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cloud-sql-python-connector) (2.7.0)\n",
            "Requirement already satisfied: Requests in /usr/local/lib/python3.11/dist-packages (from cloud-sql-python-connector) (2.32.3)\n",
            "Requirement already satisfied: google-auth>=2.28.0 in /usr/local/lib/python3.11/dist-packages (from cloud-sql-python-connector) (2.38.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=42.0.0->cloud-sql-python-connector) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.28.0->cloud-sql-python-connector) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.28.0->cloud-sql-python-connector) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.28.0->cloud-sql-python-connector) (4.9)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from Requests->cloud-sql-python-connector) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from Requests->cloud-sql-python-connector) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from Requests->cloud-sql-python-connector) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from Requests->cloud-sql-python-connector) (2025.1.31)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=42.0.0->cloud-sql-python-connector) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.28.0->cloud-sql-python-connector) (0.6.1)\n",
            "Downloading cloud_sql_python_connector-1.17.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: aiofiles, cloud-sql-python-connector\n",
            "Successfully installed aiofiles-24.1.0 cloud-sql-python-connector-1.17.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "86159da4da6144bfa91fd6305e3af73c",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install pymysql sqlalchemy\n",
        "!pip install cloud-sql-python-connector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "_77El1Q5lQVM",
        "outputId": "55a54c9f-391a-47f1-e24a-add139f0aa60"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;ipython-input-</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">95</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">-ce8c90bfff9e&gt;:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">30</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> RemovedIn20Warning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Deprecated API features detected! These </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">feature(</span><span style=\"color: #808000; text-decoration-color: #808000\">s</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\"> are not compatible with SQLAlchemy </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2.0</span><span style=\"color: #808000; text-decoration-color: #808000\">. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to </span><span style=\"color: #808000; text-decoration-color: #808000\">\"sqlalchemy&lt;2.0\"</span><span style=\"color: #808000; text-decoration-color: #808000\">. Set environment variable </span><span style=\"color: #808000; text-decoration-color: #808000\">SQLALCHEMY_WARN_20</span><span style=\"color: #808000; text-decoration-color: #808000\">=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\"> to show all deprecation warnings.  Set environment variable </span><span style=\"color: #808000; text-decoration-color: #808000\">SQLALCHEMY_SILENCE_UBER_WARNING</span><span style=\"color: #808000; text-decoration-color: #808000\">=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\"> to silence this message. </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">Background on SQLAlchemy </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2.0</span><span style=\"color: #808000; text-decoration-color: #808000\"> at: </span><span style=\"color: #808000; text-decoration-color: #808000; text-decoration: underline\">https://sqlalche.me/e/b8d9)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;33m<\u001b[0m\u001b[1;33mipython-input-\u001b[0m\u001b[1;33m95\u001b[0m\u001b[1;33m-ce8c90bfff9e\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m30\u001b[0m\u001b[1;33m RemovedIn20Warning\u001b[0m\u001b[33m: Deprecated API features detected! These \u001b[0m\u001b[1;33mfeature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m are not compatible with SQLAlchemy \u001b[0m\u001b[1;33m2.0\u001b[0m\u001b[33m. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \u001b[0m\u001b[33m\"sqlalchemy<2.0\"\u001b[0m\u001b[33m. Set environment variable \u001b[0m\u001b[33mSQLALCHEMY_WARN_20\u001b[0m\u001b[33m=\u001b[0m\u001b[1;33m1\u001b[0m\u001b[33m to show all deprecation warnings.  Set environment variable \u001b[0m\u001b[33mSQLALCHEMY_SILENCE_UBER_WARNING\u001b[0m\u001b[33m=\u001b[0m\u001b[1;33m1\u001b[0m\u001b[33m to silence this message. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on SQLAlchemy \u001b[0m\u001b[1;33m2.0\u001b[0m\u001b[33m at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/b8d9\u001b[0m\u001b[4;33m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Banco de dados 'Pet_Adota' criado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "from google.cloud.sql.connector import Connector\n",
        "import sqlalchemy\n",
        "\n",
        "instance_connection_name = \"projeto-mari-452814:us-central1:colab\"\n",
        "db_user = \"root\"\n",
        "db_pass = \"\"\n",
        "\n",
        "connector = Connector()\n",
        "\n",
        "def getconn():\n",
        "    conn = connector.connect(\n",
        "        instance_connection_name,\n",
        "        \"pymysql\",\n",
        "        user=db_user,\n",
        "        password=db_pass\n",
        "    )\n",
        "    return conn\n",
        "\n",
        "pool = sqlalchemy.create_engine(\n",
        "    \"mysql+pymysql://\",\n",
        "    creator=getconn,\n",
        ")\n",
        "\n",
        "with pool.connect() as db_conn:\n",
        "    db_conn.execute(\"CREATE DATABASE IF NOT EXISTS Pet_Adota\")\n",
        "    print(\"Banco de dados 'Pet_Adota' criado com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ26WfxzlZkB",
        "outputId": "52c7514d-e3c0-4c00-9a83-fa297f2379c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       raca      tipo  visualizacoes\n",
            "0  labrador  cachorro            100\n",
            "1    siames      gato             50\n",
            "2    poodle  cachorro             75\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = [\n",
        "    (\"labrador\", \"cachorro\", 100),\n",
        "    (\"siames\", \"gato\", 50),\n",
        "    (\"poodle\", \"cachorro\", 75),\n",
        "]\n",
        "\n",
        "df_estatisticas = pd.DataFrame(data, columns=[\"raca\", \"tipo\", \"visualizacoes\"])\n",
        "print(df_estatisticas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "9XTM_-JDm7He",
        "outputId": "0b5ee2a0-284b-4f03-a8cf-58cc549767bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;ipython-input-</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">104</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">-d9f89e9e9358&gt;:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">63</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> UserWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: pandas only supports SQLAlchemy connectable </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">engine/connection</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\"> or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;33m<\u001b[0m\u001b[1;33mipython-input-\u001b[0m\u001b[1;33m104\u001b[0m\u001b[1;33m-d9f89e9e9358\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m63\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: pandas only supports SQLAlchemy connectable \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mengine/connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AttributeError",
          "evalue": "'Engine' object has no attribute 'cursor'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-d9f89e9e9358>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Salvar o DataFrame no MySQL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m df_estatisticas.to_sql(\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"estatisticas_animais\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Nome da tabela\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m                     \u001b[0;31m# Usar o pool de conexões SQLAlchemy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3087\u001b[0;31m         return sql.to_sql(\n\u001b[0m\u001b[1;32m   3088\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_transaction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m         return pandas_sql.to_sql(\n\u001b[0m\u001b[1;32m    843\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   2848\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m         )\n\u001b[0;32m-> 2850\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2851\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fail\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Table '{self.name}' already exists.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msql_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mhas_table\u001b[0;34m(self, name, schema)\u001b[0m\n\u001b[1;32m   2863\u001b[0m         \"\"\"\n\u001b[1;32m   2864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2865\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2867\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Query must be a string unless using sqlalchemy.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m         \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Engine' object has no attribute 'cursor'"
          ]
        }
      ],
      "source": [
        "from google.cloud.sql.connector import Connector\n",
        "import pymysql\n",
        "import sqlalchemy\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.engine import base\n",
        "\n",
        "instance_connection_name = \"projeto-mari-452814:us-central1:colab\"\n",
        "db_user = \"root\"\n",
        "db_pass = \"\"\n",
        "db_name = \"Pet_Adota\"\n",
        "\n",
        "connector = Connector()\n",
        "\n",
        "def getconn():\n",
        "    conn = connector.connect(\n",
        "        instance_connection_name,\n",
        "        \"pymysql\",\n",
        "        user=db_user,\n",
        "        password=db_pass,\n",
        "        db=db_name\n",
        "    )\n",
        "    return conn\n",
        "\n",
        "class MySQLConnection(base.Connection):\n",
        "    def __init__(self, conn):\n",
        "        self.conn = conn\n",
        "        self.cursor = conn.cursor()\n",
        "\n",
        "    def execute(self, sql, params=None):\n",
        "        return self.cursor.execute(sql, params)\n",
        "\n",
        "    def close(self):\n",
        "        self.cursor.close()\n",
        "        self.conn.close()\n",
        "\n",
        "\n",
        "def get_sqlalchemy_engine():\n",
        "    return create_engine(\n",
        "        \"mysql+pymysql://\",\n",
        "        creator=lambda: MySQLConnection(getconn())\n",
        "    )\n",
        "\n",
        "pool = get_sqlalchemy_engine()\n",
        "\n",
        "data = [\n",
        "    (\"labrador\", \"cachorro\", 100),\n",
        "    (\"siames\", \"gato\", 50),\n",
        "    (\"poodle\", \"cachorro\", 75),\n",
        "]\n",
        "\n",
        "df_estatisticas = pd.DataFrame(data, columns=[\"raca\", \"tipo\", \"visualizacoes\"])\n",
        "\n",
        "df_estatisticas.to_sql(\n",
        "    name=\"estatisticas_animais\",\n",
        "    con=pool,\n",
        "    if_exists=\"append\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(\"Estatísticas salvas no MySQL com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjWaIU3ioazi",
        "outputId": "46b7d4ea-6872-4cc6-f11d-5da72daf9abc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conexão bem-sucedida!\n",
            "Tabela 'estatisticas_animais' criada com sucesso!\n",
            "Estatísticas salvas no MySQL com sucesso!\n",
            "Conexão fechada.\n"
          ]
        }
      ],
      "source": [
        "import pymysql\n",
        "import pandas as pd\n",
        "\n",
        "host = \"35.188.171.159\"\n",
        "user = \"root\"\n",
        "password = \"\"\n",
        "database = \"Pet_Adota\"\n",
        "\n",
        "data = [\n",
        "    (\"labrador\", \"cachorro\", 100),\n",
        "    (\"siames\", \"gato\", 50),\n",
        "    (\"poodle\", \"cachorro\", 75),\n",
        "]\n",
        "\n",
        "df_estatisticas = pd.DataFrame(data, columns=[\"raca\", \"tipo\", \"visualizacoes\"])\n",
        "\n",
        "connection = None\n",
        "\n",
        "try:\n",
        "    connection = pymysql.connect(\n",
        "        host=host,\n",
        "        user=user,\n",
        "        password=password,\n",
        "        database=database\n",
        "    )\n",
        "    print(\"Conexão bem-sucedida!\")\n",
        "\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    create_table_query = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS estatisticas_animais (\n",
        "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "        raca VARCHAR(255) NOT NULL,\n",
        "        tipo VARCHAR(255) NOT NULL,\n",
        "        visualizacoes INT NOT NULL,\n",
        "        data_registro TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "    );\n",
        "    \"\"\"\n",
        "    cursor.execute(create_table_query)\n",
        "    print(\"Tabela 'estatisticas_animais' criada com sucesso!\")\n",
        "\n",
        "    for index, row in df_estatisticas.iterrows():\n",
        "        insert_query = \"\"\"\n",
        "        INSERT INTO estatisticas_animais (raca, tipo, visualizacoes)\n",
        "        VALUES (%s, %s, %s)\n",
        "        \"\"\"\n",
        "        cursor.execute(insert_query, (row[\"raca\"], row[\"tipo\"], row[\"visualizacoes\"]))\n",
        "\n",
        "    connection.commit()\n",
        "    print(\"Estatísticas salvas no MySQL com sucesso!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao conectar ou salvar dados no MySQL: {e}\")\n",
        "\n",
        "finally:\n",
        "    if connection:\n",
        "        connection.close()\n",
        "        print(\"Conexão fechada.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CFpt33UowEC",
        "outputId": "f32f45c4-d353-4bfb-8de9-afea764e2dd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Task(PythonOperator): processar_tendencias>"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python import PythonOperator\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import pymysql\n",
        "\n",
        "def processar_tendencias():\n",
        "    host = \"35.188.171.159\"\n",
        "    user = \"root\"\n",
        "    password = \"\"\n",
        "    database = \"Pet_Adota\"\n",
        "\n",
        "    try:\n",
        "        connection = pymysql.connect(\n",
        "            host=host,\n",
        "            user=user,\n",
        "            password=password,\n",
        "            database=database\n",
        "        )\n",
        "        print(\"Conexão bem-sucedida!\")\n",
        "\n",
        "        query = \"\"\"\n",
        "        SELECT raca, tipo, SUM(visualizacoes) AS total_visualizacoes\n",
        "        FROM estatisticas_animais\n",
        "        GROUP BY raca, tipo\n",
        "        ORDER BY total_visualizacoes DESC;\n",
        "        \"\"\"\n",
        "        df_tendencias = pd.read_sql(query, connection)\n",
        "        print(\"Tendências encontradas:\")\n",
        "        print(df_tendencias)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar tendências: {e}\")\n",
        "\n",
        "    finally:\n",
        "        if connection:\n",
        "            connection.close()\n",
        "            print(\"Conexão fechada.\")\n",
        "\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'depends_on_past': False,\n",
        "    'start_date': datetime(2023, 10, 25),\n",
        "    'retries': 1,\n",
        "    'retry_delay': timedelta(seconds=5),\n",
        "}\n",
        "\n",
        "dag = DAG(\n",
        "    'visualizar_tendencias',\n",
        "    default_args=default_args,\n",
        "    description='DAG para visualizar tendências a cada 30 segundos',\n",
        "    schedule=timedelta(seconds=30),  # Usando 'schedule' em vez de 'schedule_interval'\n",
        "    catchup=False,\n",
        ")\n",
        "\n",
        "tarefa_processar_tendencias = PythonOperator(\n",
        "    task_id='processar_tendencias',\n",
        "    python_callable=processar_tendencias,\n",
        "    dag=dag,\n",
        ")\n",
        "\n",
        "tarefa_processar_tendencias"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}